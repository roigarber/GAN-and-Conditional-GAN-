{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CnfUt6NWs2k"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7aubPIDWs2u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io.arff import loadarff\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPOAXXIKWs2z"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuU0ThpDWs20"
      },
      "outputs": [],
      "source": [
        "class DataPreprocessor:\n",
        "    def __init__(self):\n",
        "        self.continuous_features = ['age', 'fnlwgt', 'education-num', 'capital-gain',\n",
        "                                  'capital-loss', 'hours-per-week']\n",
        "        self.categorical_features = ['workclass', 'education', 'marital-status',\n",
        "                                   'occupation', 'relationship', 'race', 'sex',\n",
        "                                   'native-country']\n",
        "        self.target = 'income'\n",
        "\n",
        "        self.scalers = {}\n",
        "        self.encoders = {}\n",
        "        self.feature_dims = {}\n",
        "\n",
        "    def load_and_preprocess(self, arff_path, random_seed=42):\n",
        "        # Load ARFF file\n",
        "        data, meta = loadarff(arff_path)\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        # Convert bytes to string for categorical columns\n",
        "        for col in df.select_dtypes(include=['object']):\n",
        "            df[col] = df[col].str.decode('utf-8')\n",
        "\n",
        "        # Process continuous features\n",
        "        for feat in self.continuous_features:\n",
        "            scaler = MinMaxScaler()\n",
        "            df[feat] = scaler.fit_transform(df[[feat]])\n",
        "            self.scalers[feat] = scaler\n",
        "            self.feature_dims[feat] = 1\n",
        "\n",
        "        # Process categorical features\n",
        "        for feat in self.categorical_features:\n",
        "            encoder = OneHotEncoder(sparse_output=False)\n",
        "            encoded = encoder.fit_transform(df[[feat]])\n",
        "\n",
        "            # Create new column names\n",
        "            feat_names = [f\"{feat}_{val}\" for val in encoder.categories_[0]]\n",
        "\n",
        "            # Replace original column with encoded columns\n",
        "            df = df.drop(columns=[feat])\n",
        "            for i, name in enumerate(feat_names):\n",
        "                df[name] = encoded[:, i]\n",
        "\n",
        "            self.encoders[feat] = encoder\n",
        "            self.feature_dims[feat] = len(encoder.categories_[0])\n",
        "\n",
        "        # Encode target\n",
        "        target_encoder = LabelEncoder()\n",
        "        df[self.target] = target_encoder.fit_transform(df[self.target])\n",
        "        self.encoders[self.target] = target_encoder\n",
        "\n",
        "        # Split into features and target\n",
        "        X = df.drop(columns=[self.target])\n",
        "        y = df[self.target]\n",
        "\n",
        "        # Create train/test split maintaining label ratios\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=random_seed, stratify=y\n",
        "        )\n",
        "\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    @property\n",
        "    def input_dim(self):\n",
        "        return sum(dim for dim in self.feature_dims.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-YoQGeHWs21"
      },
      "source": [
        "## Generator Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAp1hQZAWs22"
      },
      "outputs": [],
      "source": [
        "class BaseGenerator(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Linear(1024, output_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYSUdqRvWs24"
      },
      "outputs": [],
      "source": [
        "class Generator(BaseGenerator):\n",
        "    def __init__(self, noise_dim, output_dim):\n",
        "        super().__init__(noise_dim, output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW_uA0O9Ws25"
      },
      "outputs": [],
      "source": [
        "class ConditionalGenerator(BaseGenerator):\n",
        "    def __init__(self, noise_dim, label_dim, output_dim):\n",
        "        super().__init__(noise_dim + label_dim, output_dim)\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        input_data = torch.cat((noise, labels), dim=1)\n",
        "        return super().forward(input_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9wMRetaWs27"
      },
      "source": [
        "## Discriminator Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsIGVrMpWs28"
      },
      "outputs": [],
      "source": [
        "class BaseDiscriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CUEuAycWs29"
      },
      "outputs": [],
      "source": [
        "class Discriminator(BaseDiscriminator):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__(input_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9di8q3DWWs2_"
      },
      "outputs": [],
      "source": [
        "class ConditionalDiscriminator(BaseDiscriminator):\n",
        "    def __init__(self, input_dim, label_dim):\n",
        "        super().__init__(input_dim + label_dim)\n",
        "\n",
        "    def forward(self, data, labels):\n",
        "        input_data = torch.cat((data, labels), dim=1)\n",
        "        return super().forward(input_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taUXROW6Ws3A"
      },
      "source": [
        "## GANS Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2YOWAqxWs3A"
      },
      "outputs": [],
      "source": [
        "class BaseGAN:\n",
        "    def __init__(self, generator, discriminator, lr=0.0002):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.generator = generator.to(self.device)\n",
        "        self.discriminator = discriminator.to(self.device)\n",
        "        self.noise_dim = getattr(self.generator, 'noise_dim', 100)\n",
        "\n",
        "        self.g_optimizer = optim.Adam(self.generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "        self.d_optimizer = optim.Adam(self.discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "        self.criterion = nn.BCELoss()\n",
        "\n",
        "    def _train_discriminator(self, real_data, real_labels=None):\n",
        "        batch_size = real_data.size(0)\n",
        "        label_real = torch.ones(batch_size, 1).to(self.device)\n",
        "        label_fake = torch.zeros(batch_size, 1).to(self.device)\n",
        "\n",
        "        self.d_optimizer.zero_grad()\n",
        "\n",
        "        if real_labels is not None:\n",
        "            d_output_real = self.discriminator(real_data, real_labels)\n",
        "            noise = torch.randn(batch_size, self.noise_dim).to(self.device)\n",
        "            fake_data = self.generator(noise, real_labels)\n",
        "            d_output_fake = self.discriminator(fake_data.detach(), real_labels)\n",
        "        else:\n",
        "            d_output_real = self.discriminator(real_data)\n",
        "            noise = torch.randn(batch_size, self.noise_dim).to(self.device)\n",
        "            fake_data = self.generator(noise)\n",
        "            d_output_fake = self.discriminator(fake_data.detach())\n",
        "\n",
        "        d_loss_real = self.criterion(d_output_real, label_real)\n",
        "        d_loss_fake = self.criterion(d_output_fake, label_fake)\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "        d_loss.backward()\n",
        "        self.d_optimizer.step()\n",
        "\n",
        "        return d_loss, fake_data\n",
        "\n",
        "    def _train_generator(self, fake_data, real_labels=None):\n",
        "        batch_size = fake_data.size(0)\n",
        "        label_real = torch.ones(batch_size, 1).to(self.device)\n",
        "\n",
        "        self.g_optimizer.zero_grad()\n",
        "\n",
        "        if real_labels is not None:\n",
        "            fake_output = self.discriminator(fake_data, real_labels)\n",
        "        else:\n",
        "            fake_output = self.discriminator(fake_data)\n",
        "\n",
        "        g_loss = self.criterion(fake_output, label_real)\n",
        "        g_loss.backward()\n",
        "        self.g_optimizer.step()\n",
        "\n",
        "        return g_loss\n",
        "\n",
        "    def train(self, train_data, train_labels=None, epochs=20, batch_size=64):\n",
        "        if train_labels is not None:\n",
        "            dataset = list(zip(train_data, train_labels))\n",
        "        else:\n",
        "            dataset = train_data\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "        history = defaultdict(list)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            d_losses, g_losses = [], []\n",
        "\n",
        "            pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
        "            for batch in pbar:\n",
        "                if train_labels is not None:\n",
        "                    real_data, real_labels = batch\n",
        "                    real_data, real_labels = real_data.to(self.device), real_labels.to(self.device)\n",
        "                    d_loss, fake_data = self._train_discriminator(real_data, real_labels)\n",
        "                    g_loss = self._train_generator(fake_data, real_labels)\n",
        "                else:\n",
        "                    real_data = batch\n",
        "                    real_data = real_data.to(self.device)\n",
        "                    d_loss, fake_data = self._train_discriminator(real_data)\n",
        "                    g_loss = self._train_generator(fake_data)\n",
        "\n",
        "                d_losses.append(d_loss.item())\n",
        "                g_losses.append(g_loss.item())\n",
        "\n",
        "                pbar.set_postfix({\n",
        "                    'D_loss': f'{np.mean(d_losses):.4f}',\n",
        "                    'G_loss': f'{np.mean(g_losses):.4f}'\n",
        "                })\n",
        "\n",
        "            history['d_losses'].append(np.mean(d_losses))\n",
        "            history['g_losses'].append(np.mean(g_losses))\n",
        "\n",
        "        return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWXf_hjsWs3B"
      },
      "outputs": [],
      "source": [
        "class GAN(BaseGAN):\n",
        "    def __init__(self, input_dim, noise_dim=100, lr=0.0002):\n",
        "        generator = Generator(noise_dim, input_dim)\n",
        "        discriminator = Discriminator(input_dim)\n",
        "        super().__init__(generator, discriminator, lr)\n",
        "\n",
        "    def generate_samples(self, num_samples):\n",
        "        self.generator.eval()\n",
        "        with torch.no_grad():\n",
        "            noise = torch.randn(num_samples, self.noise_dim).to(self.device)\n",
        "            fake_data = self.generator(noise)\n",
        "        return fake_data.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1puYvV8Ws3B"
      },
      "outputs": [],
      "source": [
        "class ConditionalGAN(BaseGAN):\n",
        "    def __init__(self, input_dim, label_dim, noise_dim=100, lr=0.0002):\n",
        "        generator = ConditionalGenerator(noise_dim, label_dim, input_dim)\n",
        "        discriminator = ConditionalDiscriminator(input_dim, label_dim)\n",
        "        super().__init__(generator, discriminator, lr)\n",
        "\n",
        "    def generate_samples(self, num_samples, labels):\n",
        "        self.generator.eval()\n",
        "        with torch.no_grad():\n",
        "            noise = torch.randn(num_samples, self.noise_dim).to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            fake_data = self.generator(noise, labels)\n",
        "        return fake_data.cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqs-h1HWWs3C"
      },
      "source": [
        "## Trianing GANS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkyNnE6-Ws3C"
      },
      "outputs": [],
      "source": [
        "def run_experiment_GAN(arff_path, random_seed):\n",
        "    # Initialize preprocessor and load data\n",
        "    preprocessor = DataPreprocessor()\n",
        "    X_train, X_test, y_train, y_test = preprocessor.load_and_preprocess(\n",
        "        arff_path, random_seed=random_seed\n",
        "    )\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    train_data = torch.FloatTensor(X_train.values)\n",
        "\n",
        "    # Initialize and train GAN\n",
        "    gan = GAN(input_dim=preprocessor.input_dim)\n",
        "    history = gan.train(train_data, epochs=100, batch_size=64)\n",
        "\n",
        "    # Generate synthetic samples\n",
        "    synthetic_samples = gan.generate_samples(len(X_train))\n",
        "\n",
        "    return history, synthetic_samples, (X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_y6cJMvWs3C"
      },
      "outputs": [],
      "source": [
        "def run_experiment_CGAN(arff_path, random_seed):\n",
        "    \"\"\"\n",
        "    Run experiment for cGAN.\n",
        "    \"\"\"\n",
        "    # Initialize preprocessor and load data\n",
        "    preprocessor = DataPreprocessor()\n",
        "    X_train, X_test, y_train, y_test = preprocessor.load_and_preprocess(\n",
        "        arff_path, random_seed=random_seed\n",
        "    )\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    train_data = torch.FloatTensor(X_train.values)\n",
        "    train_labels = torch.FloatTensor(pd.get_dummies(y_train).values)  # One-hot encode labels\n",
        "\n",
        "    # Initialize and train cGAN\n",
        "    cgan = ConditionalGAN(input_dim=preprocessor.input_dim, label_dim=train_labels.size(1))\n",
        "    history = cgan.train(train_data, train_labels, epochs=100, batch_size=64)\n",
        "\n",
        "    # Generate synthetic samples\n",
        "    synthetic_labels = torch.FloatTensor(pd.get_dummies(y_train).values).to(cgan.device)  # Use training labels\n",
        "    synthetic_samples = cgan.generate_samples(len(X_train), synthetic_labels)\n",
        "\n",
        "    return history, synthetic_samples, (X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation metrics"
      ],
      "metadata": {
        "id": "Cx78X0sXkz8G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvDTUWQ1Ws3D"
      },
      "outputs": [],
      "source": [
        "def detection_metric(real_data, synthetic_data):\n",
        "    \"\"\"\n",
        "    Evaluate the detection metric with stratified folds to maintain label distribution.\n",
        "    \"\"\"\n",
        "    # Combine real and synthetic data\n",
        "    combined_X = np.vstack((real_data, synthetic_data))\n",
        "    combined_y = np.hstack((\n",
        "        np.ones(len(real_data)),  # Label real as 1\n",
        "        np.zeros(len(synthetic_data))  # Label synthetic as 0\n",
        "    ))\n",
        "\n",
        "    # Stratified cross-validation setup\n",
        "    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "    auc_scores = []\n",
        "\n",
        "    for train_idx, test_idx in skf.split(combined_X, combined_y):\n",
        "        X_train, X_test = combined_X[train_idx], combined_X[test_idx]\n",
        "        y_train, y_test = combined_y[train_idx], combined_y[test_idx]\n",
        "\n",
        "        # Train Random Forest\n",
        "        model = RandomForestClassifier(random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Predict probabilities and calculate AUC\n",
        "        y_pred = model.predict_proba(X_test)[:, 1]\n",
        "        auc = roc_auc_score(y_test, y_pred)\n",
        "        auc_scores.append(auc)\n",
        "\n",
        "    return np.mean(auc_scores)\n",
        "\n",
        "\n",
        "def efficacy_metric(real_train, real_test, real_labels, synthetic_train, synthetic_labels, test_labels):\n",
        "    \"\"\"\n",
        "    Evaluate the efficacy metric.\n",
        "    \"\"\"\n",
        "    # Train on real data, test on real data\n",
        "    rf_real = RandomForestClassifier(random_state=42)\n",
        "    rf_real.fit(real_train, real_labels)\n",
        "    real_auc = roc_auc_score(test_labels, rf_real.predict_proba(real_test)[:, 1])\n",
        "\n",
        "\n",
        "    # Train on synthetic data, test on real data\n",
        "    rf_synthetic = RandomForestClassifier(random_state=42)\n",
        "    rf_synthetic.fit(synthetic_train, synthetic_labels)\n",
        "    synthetic_auc = roc_auc_score(test_labels, rf_synthetic.predict_proba(real_test)[:, 1])\n",
        "\n",
        "    # Compute efficacy ratio\n",
        "    efficacy_ratio = synthetic_auc / real_auc\n",
        "    return real_auc, synthetic_auc, efficacy_ratio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {
        "id": "InIBdoHak5F6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw9-Qs1SWs3D",
        "outputId": "394487c8-b9c7-4efb-c90e-d569917d0a4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running experiment with seed 42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "Epoch 1/100: 100%|██████████| 407/407 [00:10<00:00, 38.77it/s, D_loss=0.5194, G_loss=7.9320] \n",
            "Epoch 2/100: 100%|██████████| 407/407 [00:02<00:00, 195.31it/s, D_loss=0.3799, G_loss=7.2238]\n",
            "Epoch 3/100: 100%|██████████| 407/407 [00:02<00:00, 195.58it/s, D_loss=0.2986, G_loss=5.8498]\n",
            "Epoch 4/100: 100%|██████████| 407/407 [00:02<00:00, 198.10it/s, D_loss=0.3218, G_loss=4.4395]\n",
            "Epoch 5/100: 100%|██████████| 407/407 [00:02<00:00, 195.26it/s, D_loss=0.3330, G_loss=3.0974]\n",
            "Epoch 6/100: 100%|██████████| 407/407 [00:02<00:00, 194.41it/s, D_loss=0.3002, G_loss=3.0449]\n",
            "Epoch 7/100: 100%|██████████| 407/407 [00:02<00:00, 196.82it/s, D_loss=0.3251, G_loss=2.9515]\n",
            "Epoch 8/100: 100%|██████████| 407/407 [00:02<00:00, 199.88it/s, D_loss=0.3475, G_loss=2.7794]\n",
            "Epoch 9/100: 100%|██████████| 407/407 [00:02<00:00, 197.29it/s, D_loss=0.3271, G_loss=2.7806]\n",
            "Epoch 10/100: 100%|██████████| 407/407 [00:02<00:00, 198.91it/s, D_loss=0.3502, G_loss=2.6919]\n",
            "Epoch 11/100: 100%|██████████| 407/407 [00:02<00:00, 196.55it/s, D_loss=0.3418, G_loss=2.6587]\n",
            "Epoch 12/100: 100%|██████████| 407/407 [00:02<00:00, 198.31it/s, D_loss=0.3173, G_loss=2.7067]\n",
            "Epoch 13/100: 100%|██████████| 407/407 [00:02<00:00, 195.09it/s, D_loss=0.3560, G_loss=2.5597]\n",
            "Epoch 14/100: 100%|██████████| 407/407 [00:02<00:00, 197.30it/s, D_loss=0.3527, G_loss=2.5411]\n",
            "Epoch 15/100: 100%|██████████| 407/407 [00:02<00:00, 195.80it/s, D_loss=0.3615, G_loss=2.4807]\n",
            "Epoch 16/100: 100%|██████████| 407/407 [00:02<00:00, 198.08it/s, D_loss=0.3500, G_loss=2.4910]\n",
            "Epoch 17/100: 100%|██████████| 407/407 [00:02<00:00, 199.36it/s, D_loss=0.3581, G_loss=2.4952]\n",
            "Epoch 18/100: 100%|██████████| 407/407 [00:02<00:00, 198.89it/s, D_loss=0.3580, G_loss=2.4691]\n",
            "Epoch 19/100: 100%|██████████| 407/407 [00:02<00:00, 199.85it/s, D_loss=0.3750, G_loss=2.4126]\n",
            "Epoch 20/100: 100%|██████████| 407/407 [00:02<00:00, 194.23it/s, D_loss=0.3773, G_loss=2.3716]\n",
            "Epoch 21/100: 100%|██████████| 407/407 [00:02<00:00, 197.63it/s, D_loss=0.3815, G_loss=2.3764]\n",
            "Epoch 22/100: 100%|██████████| 407/407 [00:02<00:00, 197.33it/s, D_loss=0.3838, G_loss=2.3519]\n",
            "Epoch 23/100: 100%|██████████| 407/407 [00:02<00:00, 199.97it/s, D_loss=0.3831, G_loss=2.3532]\n",
            "Epoch 24/100: 100%|██████████| 407/407 [00:02<00:00, 197.18it/s, D_loss=0.3825, G_loss=2.3630]\n",
            "Epoch 25/100: 100%|██████████| 407/407 [00:02<00:00, 198.69it/s, D_loss=0.3946, G_loss=2.3503]\n",
            "Epoch 26/100: 100%|██████████| 407/407 [00:02<00:00, 197.35it/s, D_loss=0.3864, G_loss=2.3297]\n",
            "Epoch 27/100: 100%|██████████| 407/407 [00:02<00:00, 195.79it/s, D_loss=0.3840, G_loss=2.3443]\n",
            "Epoch 28/100: 100%|██████████| 407/407 [00:02<00:00, 196.84it/s, D_loss=0.3822, G_loss=2.3592]\n",
            "Epoch 29/100: 100%|██████████| 407/407 [00:02<00:00, 196.14it/s, D_loss=0.3818, G_loss=2.3744]\n",
            "Epoch 30/100: 100%|██████████| 407/407 [00:02<00:00, 198.10it/s, D_loss=0.3824, G_loss=2.3502]\n",
            "Epoch 31/100: 100%|██████████| 407/407 [00:02<00:00, 197.80it/s, D_loss=0.3814, G_loss=2.3581]\n",
            "Epoch 32/100: 100%|██████████| 407/407 [00:02<00:00, 198.94it/s, D_loss=0.3815, G_loss=2.3613]\n",
            "Epoch 33/100: 100%|██████████| 407/407 [00:02<00:00, 196.00it/s, D_loss=0.3813, G_loss=2.3624]\n",
            "Epoch 34/100: 100%|██████████| 407/407 [00:02<00:00, 197.84it/s, D_loss=0.3815, G_loss=2.3738]\n",
            "Epoch 35/100: 100%|██████████| 407/407 [00:02<00:00, 195.45it/s, D_loss=0.3780, G_loss=2.3955]\n",
            "Epoch 36/100: 100%|██████████| 407/407 [00:02<00:00, 199.37it/s, D_loss=0.3777, G_loss=2.3975]\n",
            "Epoch 37/100: 100%|██████████| 407/407 [00:02<00:00, 198.99it/s, D_loss=0.3744, G_loss=2.4145]\n",
            "Epoch 38/100: 100%|██████████| 407/407 [00:02<00:00, 197.23it/s, D_loss=0.3738, G_loss=2.4231]\n",
            "Epoch 39/100: 100%|██████████| 407/407 [00:02<00:00, 197.01it/s, D_loss=0.3738, G_loss=2.4380]\n",
            "Epoch 40/100: 100%|██████████| 407/407 [00:02<00:00, 201.82it/s, D_loss=0.3789, G_loss=2.4224]\n",
            "Epoch 41/100: 100%|██████████| 407/407 [00:02<00:00, 199.71it/s, D_loss=0.3759, G_loss=2.4250]\n",
            "Epoch 42/100: 100%|██████████| 407/407 [00:02<00:00, 196.51it/s, D_loss=0.3719, G_loss=2.4495]\n",
            "Epoch 43/100: 100%|██████████| 407/407 [00:02<00:00, 198.65it/s, D_loss=0.3723, G_loss=2.4709]\n",
            "Epoch 44/100: 100%|██████████| 407/407 [00:02<00:00, 198.37it/s, D_loss=0.3694, G_loss=2.4841]\n",
            "Epoch 45/100: 100%|██████████| 407/407 [00:02<00:00, 196.83it/s, D_loss=0.3648, G_loss=2.5141]\n",
            "Epoch 46/100: 100%|██████████| 407/407 [00:02<00:00, 197.17it/s, D_loss=0.3660, G_loss=2.5077]\n",
            "Epoch 47/100: 100%|██████████| 407/407 [00:02<00:00, 197.58it/s, D_loss=0.3623, G_loss=2.5371]\n",
            "Epoch 48/100: 100%|██████████| 407/407 [00:02<00:00, 197.79it/s, D_loss=0.3627, G_loss=2.5422]\n",
            "Epoch 49/100: 100%|██████████| 407/407 [00:02<00:00, 200.24it/s, D_loss=0.3669, G_loss=2.5579]\n",
            "Epoch 50/100: 100%|██████████| 407/407 [00:02<00:00, 198.11it/s, D_loss=0.3674, G_loss=2.5548]\n",
            "Epoch 51/100: 100%|██████████| 407/407 [00:02<00:00, 196.85it/s, D_loss=0.3647, G_loss=2.5613]\n",
            "Epoch 52/100: 100%|██████████| 407/407 [00:02<00:00, 195.14it/s, D_loss=0.3664, G_loss=2.5824]\n",
            "Epoch 53/100: 100%|██████████| 407/407 [00:02<00:00, 200.23it/s, D_loss=0.3643, G_loss=2.5885]\n",
            "Epoch 54/100: 100%|██████████| 407/407 [00:02<00:00, 200.43it/s, D_loss=0.3623, G_loss=2.6031]\n",
            "Epoch 55/100: 100%|██████████| 407/407 [00:02<00:00, 197.48it/s, D_loss=0.3586, G_loss=2.6457]\n",
            "Epoch 56/100: 100%|██████████| 407/407 [00:02<00:00, 200.52it/s, D_loss=0.3586, G_loss=2.6463]\n",
            "Epoch 57/100: 100%|██████████| 407/407 [00:02<00:00, 196.24it/s, D_loss=0.3569, G_loss=2.6719]\n",
            "Epoch 58/100: 100%|██████████| 407/407 [00:02<00:00, 196.12it/s, D_loss=0.3578, G_loss=2.6567]\n",
            "Epoch 59/100: 100%|██████████| 407/407 [00:02<00:00, 197.96it/s, D_loss=0.3559, G_loss=2.6966]\n",
            "Epoch 60/100: 100%|██████████| 407/407 [00:02<00:00, 196.88it/s, D_loss=0.3580, G_loss=2.6775]\n",
            "Epoch 61/100: 100%|██████████| 407/407 [00:02<00:00, 200.16it/s, D_loss=0.3561, G_loss=2.7254]\n",
            "Epoch 62/100: 100%|██████████| 407/407 [00:02<00:00, 199.94it/s, D_loss=0.3534, G_loss=2.7388]\n",
            "Epoch 63/100: 100%|██████████| 407/407 [00:02<00:00, 198.77it/s, D_loss=0.3561, G_loss=2.7287]\n",
            "Epoch 64/100: 100%|██████████| 407/407 [00:02<00:00, 199.75it/s, D_loss=0.3546, G_loss=2.7446]\n",
            "Epoch 65/100: 100%|██████████| 407/407 [00:02<00:00, 200.35it/s, D_loss=0.3498, G_loss=2.7872]\n",
            "Epoch 66/100: 100%|██████████| 407/407 [00:02<00:00, 196.76it/s, D_loss=0.3481, G_loss=2.7919]\n",
            "Epoch 67/100: 100%|██████████| 407/407 [00:02<00:00, 199.88it/s, D_loss=0.3479, G_loss=2.8338]\n",
            "Epoch 68/100: 100%|██████████| 407/407 [00:02<00:00, 198.81it/s, D_loss=0.3517, G_loss=2.8289]\n",
            "Epoch 69/100: 100%|██████████| 407/407 [00:02<00:00, 199.46it/s, D_loss=0.3516, G_loss=2.8309]\n",
            "Epoch 70/100: 100%|██████████| 407/407 [00:02<00:00, 196.15it/s, D_loss=0.3492, G_loss=2.8407]\n",
            "Epoch 71/100: 100%|██████████| 407/407 [00:02<00:00, 198.72it/s, D_loss=0.3494, G_loss=2.8766]\n",
            "Epoch 72/100: 100%|██████████| 407/407 [00:02<00:00, 198.17it/s, D_loss=0.3459, G_loss=2.8706]\n",
            "Epoch 73/100: 100%|██████████| 407/407 [00:02<00:00, 195.68it/s, D_loss=0.3458, G_loss=2.9113]\n",
            "Epoch 74/100: 100%|██████████| 407/407 [00:02<00:00, 196.45it/s, D_loss=0.3419, G_loss=2.9327]\n",
            "Epoch 75/100: 100%|██████████| 407/407 [00:02<00:00, 198.63it/s, D_loss=0.3425, G_loss=2.9783]\n",
            "Epoch 76/100: 100%|██████████| 407/407 [00:02<00:00, 199.59it/s, D_loss=0.3456, G_loss=2.9581]\n",
            "Epoch 77/100: 100%|██████████| 407/407 [00:02<00:00, 196.57it/s, D_loss=0.3432, G_loss=2.9990]\n",
            "Epoch 78/100: 100%|██████████| 407/407 [00:02<00:00, 197.94it/s, D_loss=0.3441, G_loss=2.9371]\n",
            "Epoch 79/100: 100%|██████████| 407/407 [00:02<00:00, 198.07it/s, D_loss=0.3420, G_loss=2.9865]\n",
            "Epoch 80/100: 100%|██████████| 407/407 [00:02<00:00, 196.24it/s, D_loss=0.3401, G_loss=3.0212]\n",
            "Epoch 81/100: 100%|██████████| 407/407 [00:02<00:00, 197.45it/s, D_loss=0.3359, G_loss=3.0649]\n",
            "Epoch 82/100: 100%|██████████| 407/407 [00:02<00:00, 199.29it/s, D_loss=0.3348, G_loss=3.0884]\n",
            "Epoch 83/100: 100%|██████████| 407/407 [00:02<00:00, 199.53it/s, D_loss=0.3307, G_loss=3.1342]\n",
            "Epoch 84/100: 100%|██████████| 407/407 [00:02<00:00, 198.49it/s, D_loss=0.3339, G_loss=3.1321]\n",
            "Epoch 85/100: 100%|██████████| 407/407 [00:02<00:00, 195.58it/s, D_loss=0.3361, G_loss=3.1153]\n",
            "Epoch 86/100: 100%|██████████| 407/407 [00:02<00:00, 194.93it/s, D_loss=0.3388, G_loss=3.0883]\n",
            "Epoch 87/100: 100%|██████████| 407/407 [00:02<00:00, 200.12it/s, D_loss=0.3383, G_loss=3.1410]\n",
            "Epoch 88/100: 100%|██████████| 407/407 [00:02<00:00, 199.55it/s, D_loss=0.3395, G_loss=3.1141]\n",
            "Epoch 89/100: 100%|██████████| 407/407 [00:02<00:00, 199.99it/s, D_loss=0.3365, G_loss=3.1705]\n",
            "Epoch 90/100: 100%|██████████| 407/407 [00:02<00:00, 198.46it/s, D_loss=0.3340, G_loss=3.2370]\n",
            "Epoch 91/100: 100%|██████████| 407/407 [00:02<00:00, 196.82it/s, D_loss=0.3392, G_loss=3.1832]\n",
            "Epoch 92/100: 100%|██████████| 407/407 [00:02<00:00, 198.70it/s, D_loss=0.3371, G_loss=3.1777]\n",
            "Epoch 93/100: 100%|██████████| 407/407 [00:02<00:00, 200.57it/s, D_loss=0.3352, G_loss=3.2202]\n",
            "Epoch 94/100: 100%|██████████| 407/407 [00:02<00:00, 198.30it/s, D_loss=0.3349, G_loss=3.1971]\n",
            "Epoch 95/100: 100%|██████████| 407/407 [00:02<00:00, 198.45it/s, D_loss=0.3322, G_loss=3.2924]\n",
            "Epoch 96/100: 100%|██████████| 407/407 [00:02<00:00, 197.61it/s, D_loss=0.3384, G_loss=3.2434]\n",
            "Epoch 97/100: 100%|██████████| 407/407 [00:02<00:00, 195.05it/s, D_loss=0.3280, G_loss=3.4156]\n",
            "Epoch 98/100: 100%|██████████| 407/407 [00:02<00:00, 199.93it/s, D_loss=0.3868, G_loss=3.2883]\n",
            "Epoch 99/100: 100%|██████████| 407/407 [00:02<00:00, 195.61it/s, D_loss=0.3339, G_loss=3.3192]\n",
            "Epoch 100/100: 100%|██████████| 407/407 [00:02<00:00, 197.06it/s, D_loss=0.3369, G_loss=3.2885]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detection AUC (Seed 42): 1.0000\n",
            "Efficacy AUC (Real, Seed 42): 0.9071\n",
            "Efficacy AUC (Synthetic, Seed 42): 0.5543\n",
            "Efficacy Ratio (Seed 42): 0.6111\n",
            "\n",
            "Running experiment with seed 123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "Epoch 1/100: 100%|██████████| 407/407 [00:02<00:00, 199.89it/s, D_loss=0.5465, G_loss=7.9886]\n",
            "Epoch 2/100: 100%|██████████| 407/407 [00:02<00:00, 197.37it/s, D_loss=0.2852, G_loss=7.8907]\n",
            "Epoch 3/100: 100%|██████████| 407/407 [00:02<00:00, 198.82it/s, D_loss=0.2441, G_loss=6.5698]\n",
            "Epoch 4/100: 100%|██████████| 407/407 [00:02<00:00, 194.44it/s, D_loss=0.2422, G_loss=5.4420]\n",
            "Epoch 5/100: 100%|██████████| 407/407 [00:02<00:00, 197.49it/s, D_loss=0.2015, G_loss=3.9642]\n",
            "Epoch 6/100: 100%|██████████| 407/407 [00:02<00:00, 198.63it/s, D_loss=0.1841, G_loss=4.2398]\n",
            "Epoch 7/100: 100%|██████████| 407/407 [00:02<00:00, 198.24it/s, D_loss=0.2324, G_loss=3.4247]\n",
            "Epoch 8/100: 100%|██████████| 407/407 [00:02<00:00, 192.80it/s, D_loss=0.2186, G_loss=3.3685]\n",
            "Epoch 9/100: 100%|██████████| 407/407 [00:02<00:00, 199.54it/s, D_loss=0.2501, G_loss=3.1489]\n",
            "Epoch 10/100: 100%|██████████| 407/407 [00:02<00:00, 199.43it/s, D_loss=0.2554, G_loss=3.1030]\n",
            "Epoch 11/100: 100%|██████████| 407/407 [00:02<00:00, 196.73it/s, D_loss=0.2246, G_loss=3.2081]\n",
            "Epoch 12/100: 100%|██████████| 407/407 [00:02<00:00, 198.46it/s, D_loss=0.2224, G_loss=3.1127]\n",
            "Epoch 13/100: 100%|██████████| 407/407 [00:02<00:00, 198.83it/s, D_loss=0.2205, G_loss=3.0890]\n",
            "Epoch 14/100: 100%|██████████| 407/407 [00:02<00:00, 197.20it/s, D_loss=0.2204, G_loss=3.0719]\n",
            "Epoch 15/100: 100%|██████████| 407/407 [00:02<00:00, 198.71it/s, D_loss=0.2182, G_loss=3.0811]\n",
            "Epoch 16/100: 100%|██████████| 407/407 [00:02<00:00, 197.46it/s, D_loss=0.2166, G_loss=3.0463]\n",
            "Epoch 17/100: 100%|██████████| 407/407 [00:02<00:00, 197.08it/s, D_loss=0.2166, G_loss=3.0485]\n",
            "Epoch 18/100: 100%|██████████| 407/407 [00:02<00:00, 201.33it/s, D_loss=0.2417, G_loss=2.9950]\n",
            "Epoch 19/100: 100%|██████████| 407/407 [00:02<00:00, 194.82it/s, D_loss=0.2688, G_loss=2.8665]\n",
            "Epoch 20/100: 100%|██████████| 407/407 [00:02<00:00, 197.95it/s, D_loss=0.2786, G_loss=2.7740]\n",
            "Epoch 21/100: 100%|██████████| 407/407 [00:02<00:00, 196.46it/s, D_loss=0.2748, G_loss=2.7592]\n",
            "Epoch 22/100: 100%|██████████| 407/407 [00:02<00:00, 198.09it/s, D_loss=0.2704, G_loss=2.7620]\n",
            "Epoch 23/100: 100%|██████████| 407/407 [00:02<00:00, 198.64it/s, D_loss=0.2805, G_loss=2.7272]\n",
            "Epoch 24/100: 100%|██████████| 407/407 [00:02<00:00, 199.37it/s, D_loss=0.2756, G_loss=2.7172]\n",
            "Epoch 25/100: 100%|██████████| 407/407 [00:02<00:00, 196.51it/s, D_loss=0.2801, G_loss=2.7050]\n",
            "Epoch 26/100: 100%|██████████| 407/407 [00:02<00:00, 197.20it/s, D_loss=0.2797, G_loss=2.7042]\n",
            "Epoch 27/100: 100%|██████████| 407/407 [00:02<00:00, 199.65it/s, D_loss=0.2930, G_loss=2.6858]\n",
            "Epoch 28/100: 100%|██████████| 407/407 [00:02<00:00, 197.86it/s, D_loss=0.3126, G_loss=2.6056]\n",
            "Epoch 29/100: 100%|██████████| 407/407 [00:02<00:00, 197.26it/s, D_loss=0.3362, G_loss=2.5172]\n",
            "Epoch 30/100: 100%|██████████| 407/407 [00:02<00:00, 196.73it/s, D_loss=0.3486, G_loss=2.4636]\n",
            "Epoch 31/100: 100%|██████████| 407/407 [00:02<00:00, 198.36it/s, D_loss=0.3447, G_loss=2.4426]\n",
            "Epoch 32/100: 100%|██████████| 407/407 [00:02<00:00, 195.70it/s, D_loss=0.3499, G_loss=2.4326]\n",
            "Epoch 33/100: 100%|██████████| 407/407 [00:02<00:00, 195.76it/s, D_loss=0.3570, G_loss=2.4151]\n",
            "Epoch 34/100: 100%|██████████| 407/407 [00:02<00:00, 201.03it/s, D_loss=0.3572, G_loss=2.4144]\n",
            "Epoch 35/100: 100%|██████████| 407/407 [00:02<00:00, 200.32it/s, D_loss=0.3576, G_loss=2.4006]\n",
            "Epoch 36/100: 100%|██████████| 407/407 [00:02<00:00, 201.31it/s, D_loss=0.3578, G_loss=2.3964]\n",
            "Epoch 37/100: 100%|██████████| 407/407 [00:02<00:00, 200.25it/s, D_loss=0.3586, G_loss=2.3982]\n",
            "Epoch 38/100: 100%|██████████| 407/407 [00:02<00:00, 200.02it/s, D_loss=0.3567, G_loss=2.4077]\n",
            "Epoch 39/100: 100%|██████████| 407/407 [00:02<00:00, 200.99it/s, D_loss=0.3658, G_loss=2.3962]\n",
            "Epoch 40/100: 100%|██████████| 407/407 [00:02<00:00, 197.91it/s, D_loss=0.3571, G_loss=2.3901]\n",
            "Epoch 41/100: 100%|██████████| 407/407 [00:02<00:00, 197.89it/s, D_loss=0.3605, G_loss=2.3893]\n",
            "Epoch 42/100: 100%|██████████| 407/407 [00:02<00:00, 198.69it/s, D_loss=0.3570, G_loss=2.4027]\n",
            "Epoch 43/100: 100%|██████████| 407/407 [00:02<00:00, 200.51it/s, D_loss=0.3589, G_loss=2.3983]\n",
            "Epoch 44/100: 100%|██████████| 407/407 [00:02<00:00, 199.21it/s, D_loss=0.3604, G_loss=2.3839]\n",
            "Epoch 45/100: 100%|██████████| 407/407 [00:02<00:00, 200.64it/s, D_loss=0.3576, G_loss=2.3760]\n",
            "Epoch 46/100: 100%|██████████| 407/407 [00:02<00:00, 194.88it/s, D_loss=0.3585, G_loss=2.3922]\n",
            "Epoch 47/100: 100%|██████████| 407/407 [00:02<00:00, 197.48it/s, D_loss=0.3579, G_loss=2.4003]\n",
            "Epoch 48/100: 100%|██████████| 407/407 [00:02<00:00, 194.38it/s, D_loss=0.3578, G_loss=2.3904]\n",
            "Epoch 49/100: 100%|██████████| 407/407 [00:02<00:00, 199.34it/s, D_loss=0.3592, G_loss=2.3749]\n",
            "Epoch 50/100: 100%|██████████| 407/407 [00:02<00:00, 199.77it/s, D_loss=0.3605, G_loss=2.3836]\n",
            "Epoch 51/100: 100%|██████████| 407/407 [00:02<00:00, 199.41it/s, D_loss=0.3604, G_loss=2.3710]\n",
            "Epoch 52/100: 100%|██████████| 407/407 [00:02<00:00, 198.59it/s, D_loss=0.3670, G_loss=2.3873]\n",
            "Epoch 53/100: 100%|██████████| 407/407 [00:02<00:00, 196.50it/s, D_loss=0.3591, G_loss=2.3810]\n",
            "Epoch 54/100: 100%|██████████| 407/407 [00:02<00:00, 198.00it/s, D_loss=0.3576, G_loss=2.3893]\n",
            "Epoch 55/100: 100%|██████████| 407/407 [00:02<00:00, 197.24it/s, D_loss=0.3613, G_loss=2.3599]\n",
            "Epoch 56/100: 100%|██████████| 407/407 [00:02<00:00, 197.87it/s, D_loss=0.3594, G_loss=2.3913]\n",
            "Epoch 57/100: 100%|██████████| 407/407 [00:02<00:00, 197.42it/s, D_loss=0.3727, G_loss=2.3836]\n",
            "Epoch 58/100: 100%|██████████| 407/407 [00:02<00:00, 198.59it/s, D_loss=0.3579, G_loss=2.3885]\n",
            "Epoch 59/100: 100%|██████████| 407/407 [00:02<00:00, 196.40it/s, D_loss=0.3659, G_loss=2.3768]\n",
            "Epoch 60/100: 100%|██████████| 407/407 [00:02<00:00, 198.83it/s, D_loss=0.3603, G_loss=2.3780]\n",
            "Epoch 61/100: 100%|██████████| 407/407 [00:02<00:00, 199.58it/s, D_loss=0.3573, G_loss=2.3851]\n",
            "Epoch 62/100: 100%|██████████| 407/407 [00:02<00:00, 199.26it/s, D_loss=0.3598, G_loss=2.3876]\n",
            "Epoch 63/100: 100%|██████████| 407/407 [00:02<00:00, 197.56it/s, D_loss=0.3611, G_loss=2.3723]\n",
            "Epoch 64/100: 100%|██████████| 407/407 [00:02<00:00, 197.29it/s, D_loss=0.3574, G_loss=2.3872]\n",
            "Epoch 65/100: 100%|██████████| 407/407 [00:02<00:00, 200.65it/s, D_loss=0.3589, G_loss=2.3945]\n",
            "Epoch 66/100: 100%|██████████| 407/407 [00:02<00:00, 198.17it/s, D_loss=0.3561, G_loss=2.4034]\n",
            "Epoch 67/100: 100%|██████████| 407/407 [00:02<00:00, 199.44it/s, D_loss=0.3615, G_loss=2.3809]\n",
            "Epoch 68/100: 100%|██████████| 407/407 [00:02<00:00, 199.34it/s, D_loss=0.3605, G_loss=2.3849]\n",
            "Epoch 69/100: 100%|██████████| 407/407 [00:02<00:00, 198.53it/s, D_loss=0.3577, G_loss=2.3912]\n",
            "Epoch 70/100: 100%|██████████| 407/407 [00:02<00:00, 197.87it/s, D_loss=0.3596, G_loss=2.3897]\n",
            "Epoch 71/100: 100%|██████████| 407/407 [00:02<00:00, 197.72it/s, D_loss=0.3591, G_loss=2.3882]\n",
            "Epoch 72/100: 100%|██████████| 407/407 [00:02<00:00, 197.08it/s, D_loss=0.3583, G_loss=2.3900]\n",
            "Epoch 73/100: 100%|██████████| 407/407 [00:02<00:00, 198.37it/s, D_loss=0.3575, G_loss=2.4005]\n",
            "Epoch 74/100: 100%|██████████| 407/407 [00:02<00:00, 196.11it/s, D_loss=0.3563, G_loss=2.4071]\n",
            "Epoch 75/100: 100%|██████████| 407/407 [00:02<00:00, 198.04it/s, D_loss=0.3571, G_loss=2.4126]\n",
            "Epoch 76/100: 100%|██████████| 407/407 [00:02<00:00, 197.77it/s, D_loss=0.3585, G_loss=2.3970]\n",
            "Epoch 77/100: 100%|██████████| 407/407 [00:02<00:00, 197.60it/s, D_loss=0.3567, G_loss=2.4026]\n",
            "Epoch 78/100: 100%|██████████| 407/407 [00:02<00:00, 198.17it/s, D_loss=0.3656, G_loss=2.4090]\n",
            "Epoch 79/100: 100%|██████████| 407/407 [00:02<00:00, 195.31it/s, D_loss=0.3581, G_loss=2.4038]\n",
            "Epoch 80/100: 100%|██████████| 407/407 [00:02<00:00, 195.30it/s, D_loss=0.3548, G_loss=2.4134]\n",
            "Epoch 81/100: 100%|██████████| 407/407 [00:02<00:00, 197.67it/s, D_loss=0.3533, G_loss=2.4230]\n",
            "Epoch 82/100: 100%|██████████| 407/407 [00:02<00:00, 200.42it/s, D_loss=0.3552, G_loss=2.4114]\n",
            "Epoch 83/100: 100%|██████████| 407/407 [00:02<00:00, 200.58it/s, D_loss=0.3524, G_loss=2.4170]\n",
            "Epoch 84/100: 100%|██████████| 407/407 [00:02<00:00, 197.69it/s, D_loss=0.3564, G_loss=2.4135]\n",
            "Epoch 85/100: 100%|██████████| 407/407 [00:02<00:00, 199.80it/s, D_loss=0.3563, G_loss=2.4064]\n",
            "Epoch 86/100: 100%|██████████| 407/407 [00:02<00:00, 198.19it/s, D_loss=0.3543, G_loss=2.4083]\n",
            "Epoch 87/100: 100%|██████████| 407/407 [00:02<00:00, 199.06it/s, D_loss=0.3538, G_loss=2.4215]\n",
            "Epoch 88/100: 100%|██████████| 407/407 [00:02<00:00, 196.06it/s, D_loss=0.3564, G_loss=2.4088]\n",
            "Epoch 89/100: 100%|██████████| 407/407 [00:02<00:00, 198.23it/s, D_loss=0.3533, G_loss=2.4118]\n",
            "Epoch 90/100: 100%|██████████| 407/407 [00:02<00:00, 201.31it/s, D_loss=0.3517, G_loss=2.4228]\n",
            "Epoch 91/100: 100%|██████████| 407/407 [00:02<00:00, 199.60it/s, D_loss=0.3499, G_loss=2.4234]\n",
            "Epoch 92/100: 100%|██████████| 407/407 [00:02<00:00, 197.59it/s, D_loss=0.3526, G_loss=2.4384]\n",
            "Epoch 93/100: 100%|██████████| 407/407 [00:02<00:00, 198.30it/s, D_loss=0.3544, G_loss=2.4146]\n",
            "Epoch 94/100: 100%|██████████| 407/407 [00:02<00:00, 196.63it/s, D_loss=0.3522, G_loss=2.4174]\n",
            "Epoch 95/100: 100%|██████████| 407/407 [00:02<00:00, 194.68it/s, D_loss=0.3515, G_loss=2.4210]\n",
            "Epoch 96/100: 100%|██████████| 407/407 [00:02<00:00, 198.54it/s, D_loss=0.3521, G_loss=2.4227]\n",
            "Epoch 97/100: 100%|██████████| 407/407 [00:02<00:00, 194.69it/s, D_loss=0.3515, G_loss=2.4299]\n",
            "Epoch 98/100: 100%|██████████| 407/407 [00:02<00:00, 196.53it/s, D_loss=0.3536, G_loss=2.4222]\n",
            "Epoch 99/100: 100%|██████████| 407/407 [00:02<00:00, 198.60it/s, D_loss=0.3548, G_loss=2.4126]\n",
            "Epoch 100/100: 100%|██████████| 407/407 [00:02<00:00, 197.79it/s, D_loss=0.3551, G_loss=2.4024]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detection AUC (Seed 123): 1.0000\n",
            "Efficacy AUC (Real, Seed 123): 0.9001\n",
            "Efficacy AUC (Synthetic, Seed 123): 0.5218\n",
            "Efficacy Ratio (Seed 123): 0.5798\n",
            "\n",
            "Running experiment with seed 456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "Epoch 1/100: 100%|██████████| 407/407 [00:02<00:00, 198.83it/s, D_loss=0.5479, G_loss=7.9773]\n",
            "Epoch 2/100: 100%|██████████| 407/407 [00:02<00:00, 199.19it/s, D_loss=0.3274, G_loss=7.5778]\n",
            "Epoch 3/100: 100%|██████████| 407/407 [00:02<00:00, 199.23it/s, D_loss=0.3093, G_loss=6.2232]\n",
            "Epoch 4/100: 100%|██████████| 407/407 [00:02<00:00, 197.04it/s, D_loss=0.3177, G_loss=3.9740]\n",
            "Epoch 5/100: 100%|██████████| 407/407 [00:02<00:00, 196.80it/s, D_loss=0.3388, G_loss=3.0156]\n",
            "Epoch 6/100: 100%|██████████| 407/407 [00:02<00:00, 199.68it/s, D_loss=0.3180, G_loss=2.9810]\n",
            "Epoch 7/100: 100%|██████████| 407/407 [00:02<00:00, 199.27it/s, D_loss=0.3302, G_loss=2.8271]\n",
            "Epoch 8/100: 100%|██████████| 407/407 [00:02<00:00, 196.73it/s, D_loss=0.2963, G_loss=2.8495]\n",
            "Epoch 9/100: 100%|██████████| 407/407 [00:02<00:00, 194.30it/s, D_loss=0.3157, G_loss=2.7608]\n",
            "Epoch 10/100: 100%|██████████| 407/407 [00:02<00:00, 199.68it/s, D_loss=0.3032, G_loss=2.7591]\n",
            "Epoch 11/100: 100%|██████████| 407/407 [00:02<00:00, 198.53it/s, D_loss=0.3023, G_loss=2.7369]\n",
            "Epoch 12/100: 100%|██████████| 407/407 [00:02<00:00, 197.57it/s, D_loss=0.3121, G_loss=2.7178]\n",
            "Epoch 13/100: 100%|██████████| 407/407 [00:02<00:00, 199.97it/s, D_loss=0.3313, G_loss=2.7101]\n",
            "Epoch 14/100: 100%|██████████| 407/407 [00:02<00:00, 199.22it/s, D_loss=0.3148, G_loss=2.7102]\n",
            "Epoch 15/100: 100%|██████████| 407/407 [00:02<00:00, 197.24it/s, D_loss=0.3188, G_loss=2.6671]\n",
            "Epoch 16/100: 100%|██████████| 407/407 [00:02<00:00, 199.94it/s, D_loss=0.3269, G_loss=2.6881]\n",
            "Epoch 17/100: 100%|██████████| 407/407 [00:02<00:00, 197.35it/s, D_loss=0.3252, G_loss=2.5959]\n",
            "Epoch 18/100: 100%|██████████| 407/407 [00:02<00:00, 198.43it/s, D_loss=0.3280, G_loss=2.5758]\n",
            "Epoch 19/100: 100%|██████████| 407/407 [00:02<00:00, 198.46it/s, D_loss=0.3447, G_loss=2.5069]\n",
            "Epoch 20/100: 100%|██████████| 407/407 [00:02<00:00, 199.38it/s, D_loss=0.3375, G_loss=2.5672]\n",
            "Epoch 21/100: 100%|██████████| 407/407 [00:02<00:00, 199.71it/s, D_loss=0.3332, G_loss=2.5660]\n",
            "Epoch 22/100: 100%|██████████| 407/407 [00:02<00:00, 198.11it/s, D_loss=0.3330, G_loss=2.5548]\n",
            "Epoch 23/100: 100%|██████████| 407/407 [00:02<00:00, 197.03it/s, D_loss=0.3321, G_loss=2.5487]\n",
            "Epoch 24/100: 100%|██████████| 407/407 [00:02<00:00, 200.04it/s, D_loss=0.3322, G_loss=2.5540]\n",
            "Epoch 25/100: 100%|██████████| 407/407 [00:02<00:00, 200.71it/s, D_loss=0.3273, G_loss=2.5727]\n",
            "Epoch 26/100: 100%|██████████| 407/407 [00:02<00:00, 199.50it/s, D_loss=0.3266, G_loss=2.5772]\n",
            "Epoch 27/100: 100%|██████████| 407/407 [00:02<00:00, 198.96it/s, D_loss=0.3205, G_loss=2.5690]\n",
            "Epoch 28/100: 100%|██████████| 407/407 [00:02<00:00, 197.83it/s, D_loss=0.3177, G_loss=2.5931]\n",
            "Epoch 29/100: 100%|██████████| 407/407 [00:02<00:00, 197.61it/s, D_loss=0.3278, G_loss=2.5470]\n",
            "Epoch 30/100: 100%|██████████| 407/407 [00:02<00:00, 198.38it/s, D_loss=0.3270, G_loss=2.5478]\n",
            "Epoch 31/100: 100%|██████████| 407/407 [00:02<00:00, 196.01it/s, D_loss=0.3373, G_loss=2.5397]\n",
            "Epoch 32/100: 100%|██████████| 407/407 [00:02<00:00, 197.71it/s, D_loss=0.3259, G_loss=2.5395]\n",
            "Epoch 33/100: 100%|██████████| 407/407 [00:02<00:00, 199.70it/s, D_loss=0.3269, G_loss=2.5400]\n",
            "Epoch 34/100: 100%|██████████| 407/407 [00:02<00:00, 198.28it/s, D_loss=0.3389, G_loss=2.5159]\n",
            "Epoch 35/100: 100%|██████████| 407/407 [00:02<00:00, 195.83it/s, D_loss=0.3436, G_loss=2.5017]\n",
            "Epoch 36/100: 100%|██████████| 407/407 [00:02<00:00, 196.46it/s, D_loss=0.3364, G_loss=2.5210]\n",
            "Epoch 37/100: 100%|██████████| 407/407 [00:02<00:00, 195.95it/s, D_loss=0.3342, G_loss=2.5248]\n",
            "Epoch 38/100: 100%|██████████| 407/407 [00:02<00:00, 198.90it/s, D_loss=0.3365, G_loss=2.5159]\n",
            "Epoch 39/100: 100%|██████████| 407/407 [00:02<00:00, 193.14it/s, D_loss=0.3433, G_loss=2.4950]\n",
            "Epoch 40/100: 100%|██████████| 407/407 [00:02<00:00, 193.89it/s, D_loss=0.3580, G_loss=2.4705]\n",
            "Epoch 41/100: 100%|██████████| 407/407 [00:02<00:00, 197.34it/s, D_loss=0.3612, G_loss=2.4656]\n",
            "Epoch 42/100: 100%|██████████| 407/407 [00:02<00:00, 197.79it/s, D_loss=0.3610, G_loss=2.4650]\n",
            "Epoch 43/100: 100%|██████████| 407/407 [00:02<00:00, 198.63it/s, D_loss=0.3579, G_loss=2.4634]\n",
            "Epoch 44/100: 100%|██████████| 407/407 [00:02<00:00, 196.74it/s, D_loss=0.3575, G_loss=2.4663]\n",
            "Epoch 45/100: 100%|██████████| 407/407 [00:02<00:00, 202.32it/s, D_loss=0.3605, G_loss=2.4560]\n",
            "Epoch 46/100: 100%|██████████| 407/407 [00:02<00:00, 197.95it/s, D_loss=0.3616, G_loss=2.4601]\n",
            "Epoch 47/100: 100%|██████████| 407/407 [00:02<00:00, 197.51it/s, D_loss=0.3594, G_loss=2.4769]\n",
            "Epoch 48/100: 100%|██████████| 407/407 [00:02<00:00, 195.60it/s, D_loss=0.3577, G_loss=2.4582]\n",
            "Epoch 49/100: 100%|██████████| 407/407 [00:02<00:00, 197.50it/s, D_loss=0.3573, G_loss=2.4843]\n",
            "Epoch 50/100: 100%|██████████| 407/407 [00:02<00:00, 195.47it/s, D_loss=0.3579, G_loss=2.4969]\n",
            "Epoch 51/100: 100%|██████████| 407/407 [00:02<00:00, 196.21it/s, D_loss=0.3558, G_loss=2.4911]\n",
            "Epoch 52/100: 100%|██████████| 407/407 [00:02<00:00, 197.38it/s, D_loss=0.3605, G_loss=2.4744]\n",
            "Epoch 53/100: 100%|██████████| 407/407 [00:02<00:00, 200.39it/s, D_loss=0.3566, G_loss=2.5022]\n",
            "Epoch 54/100: 100%|██████████| 407/407 [00:02<00:00, 199.35it/s, D_loss=0.3540, G_loss=2.5312]\n",
            "Epoch 55/100: 100%|██████████| 407/407 [00:02<00:00, 200.05it/s, D_loss=0.3512, G_loss=2.5423]\n",
            "Epoch 56/100: 100%|██████████| 407/407 [00:02<00:00, 198.51it/s, D_loss=0.3522, G_loss=2.5355]\n",
            "Epoch 57/100: 100%|██████████| 407/407 [00:02<00:00, 197.82it/s, D_loss=0.3515, G_loss=2.5602]\n",
            "Epoch 58/100: 100%|██████████| 407/407 [00:02<00:00, 201.29it/s, D_loss=0.3515, G_loss=2.5456]\n",
            "Epoch 59/100: 100%|██████████| 407/407 [00:02<00:00, 197.95it/s, D_loss=0.3509, G_loss=2.5620]\n",
            "Epoch 60/100: 100%|██████████| 407/407 [00:02<00:00, 202.18it/s, D_loss=0.3545, G_loss=2.5492]\n",
            "Epoch 61/100: 100%|██████████| 407/407 [00:02<00:00, 198.62it/s, D_loss=0.3534, G_loss=2.5495]\n",
            "Epoch 62/100: 100%|██████████| 407/407 [00:02<00:00, 195.83it/s, D_loss=0.3520, G_loss=2.5679]\n",
            "Epoch 63/100: 100%|██████████| 407/407 [00:02<00:00, 196.49it/s, D_loss=0.3513, G_loss=2.5618]\n",
            "Epoch 64/100: 100%|██████████| 407/407 [00:02<00:00, 196.87it/s, D_loss=0.3498, G_loss=2.5820]\n",
            "Epoch 65/100: 100%|██████████| 407/407 [00:02<00:00, 201.03it/s, D_loss=0.3491, G_loss=2.5894]\n",
            "Epoch 66/100: 100%|██████████| 407/407 [00:02<00:00, 194.95it/s, D_loss=0.3500, G_loss=2.6127]\n",
            "Epoch 67/100: 100%|██████████| 407/407 [00:02<00:00, 196.24it/s, D_loss=0.3506, G_loss=2.5944]\n",
            "Epoch 68/100: 100%|██████████| 407/407 [00:02<00:00, 201.38it/s, D_loss=0.3512, G_loss=2.5914]\n",
            "Epoch 69/100: 100%|██████████| 407/407 [00:01<00:00, 203.83it/s, D_loss=0.3479, G_loss=2.6196]\n",
            "Epoch 70/100: 100%|██████████| 407/407 [00:02<00:00, 197.95it/s, D_loss=0.3513, G_loss=2.6228]\n",
            "Epoch 71/100: 100%|██████████| 407/407 [00:02<00:00, 197.69it/s, D_loss=0.3483, G_loss=2.6305]\n",
            "Epoch 72/100: 100%|██████████| 407/407 [00:02<00:00, 199.44it/s, D_loss=0.3501, G_loss=2.6191]\n",
            "Epoch 73/100: 100%|██████████| 407/407 [00:02<00:00, 200.50it/s, D_loss=0.3483, G_loss=2.6164]\n",
            "Epoch 74/100: 100%|██████████| 407/407 [00:02<00:00, 198.25it/s, D_loss=0.3462, G_loss=2.6524]\n",
            "Epoch 75/100: 100%|██████████| 407/407 [00:02<00:00, 200.51it/s, D_loss=0.3459, G_loss=2.6554]\n",
            "Epoch 76/100: 100%|██████████| 407/407 [00:02<00:00, 197.14it/s, D_loss=0.3441, G_loss=2.6804]\n",
            "Epoch 77/100: 100%|██████████| 407/407 [00:02<00:00, 197.13it/s, D_loss=0.3410, G_loss=2.6950]\n",
            "Epoch 78/100: 100%|██████████| 407/407 [00:02<00:00, 199.08it/s, D_loss=0.3416, G_loss=2.7025]\n",
            "Epoch 79/100: 100%|██████████| 407/407 [00:02<00:00, 198.19it/s, D_loss=0.3440, G_loss=2.6847]\n",
            "Epoch 80/100: 100%|██████████| 407/407 [00:02<00:00, 198.96it/s, D_loss=0.3386, G_loss=2.7426]\n",
            "Epoch 81/100: 100%|██████████| 407/407 [00:02<00:00, 198.75it/s, D_loss=0.3428, G_loss=2.7425]\n",
            "Epoch 82/100: 100%|██████████| 407/407 [00:02<00:00, 197.47it/s, D_loss=0.3404, G_loss=2.7318]\n",
            "Epoch 83/100: 100%|██████████| 407/407 [00:02<00:00, 197.43it/s, D_loss=0.3381, G_loss=2.7510]\n",
            "Epoch 84/100: 100%|██████████| 407/407 [00:02<00:00, 198.69it/s, D_loss=0.3381, G_loss=2.7685]\n",
            "Epoch 85/100: 100%|██████████| 407/407 [00:02<00:00, 196.26it/s, D_loss=0.3369, G_loss=2.7886]\n",
            "Epoch 86/100: 100%|██████████| 407/407 [00:02<00:00, 199.51it/s, D_loss=0.3355, G_loss=2.7867]\n",
            "Epoch 87/100: 100%|██████████| 407/407 [00:02<00:00, 196.82it/s, D_loss=0.3379, G_loss=2.8132]\n",
            "Epoch 88/100: 100%|██████████| 407/407 [00:02<00:00, 197.51it/s, D_loss=0.3389, G_loss=2.8133]\n",
            "Epoch 89/100: 100%|██████████| 407/407 [00:02<00:00, 198.05it/s, D_loss=0.3376, G_loss=2.8526]\n",
            "Epoch 90/100: 100%|██████████| 407/407 [00:02<00:00, 195.58it/s, D_loss=0.3334, G_loss=2.9035]\n",
            "Epoch 91/100: 100%|██████████| 407/407 [00:02<00:00, 197.95it/s, D_loss=0.3357, G_loss=2.9149]\n",
            "Epoch 92/100: 100%|██████████| 407/407 [00:02<00:00, 198.20it/s, D_loss=0.3337, G_loss=2.9136]\n",
            "Epoch 93/100: 100%|██████████| 407/407 [00:02<00:00, 199.22it/s, D_loss=0.3347, G_loss=2.9215]\n",
            "Epoch 94/100: 100%|██████████| 407/407 [00:02<00:00, 198.14it/s, D_loss=0.3402, G_loss=2.8939]\n",
            "Epoch 95/100: 100%|██████████| 407/407 [00:02<00:00, 198.69it/s, D_loss=0.3316, G_loss=3.0160]\n",
            "Epoch 96/100: 100%|██████████| 407/407 [00:02<00:00, 196.93it/s, D_loss=0.3355, G_loss=2.9878]\n",
            "Epoch 97/100: 100%|██████████| 407/407 [00:02<00:00, 198.08it/s, D_loss=0.3335, G_loss=2.9821]\n",
            "Epoch 98/100: 100%|██████████| 407/407 [00:02<00:00, 198.56it/s, D_loss=0.3348, G_loss=3.0191]\n",
            "Epoch 99/100: 100%|██████████| 407/407 [00:02<00:00, 198.11it/s, D_loss=0.3351, G_loss=3.0090]\n",
            "Epoch 100/100: 100%|██████████| 407/407 [00:02<00:00, 199.00it/s, D_loss=0.3349, G_loss=3.0437]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detection AUC (Seed 456): 1.0000\n",
            "Efficacy AUC (Real, Seed 456): 0.9032\n",
            "Efficacy AUC (Synthetic, Seed 456): 0.5702\n",
            "Efficacy Ratio (Seed 456): 0.6313\n",
            "\n",
            "Summary of Detection Results:\n",
            "Seed 42: Detection AUC = 1.0000\n",
            "Seed 123: Detection AUC = 1.0000\n",
            "Seed 456: Detection AUC = 1.0000\n",
            "\n",
            "Summary of Efficacy Results:\n",
            "Seed 42: Real AUC = 0.9071, Synthetic AUC = 0.5543, Ratio = 0.6111\n",
            "Seed 123: Real AUC = 0.9001, Synthetic AUC = 0.5218, Ratio = 0.5798\n",
            "Seed 456: Real AUC = 0.9032, Synthetic AUC = 0.5702, Ratio = 0.6313\n"
          ]
        }
      ],
      "source": [
        "# Example usage for run_experiment_GAN\n",
        "if __name__ == \"__main__\":\n",
        "    arff_path = r\"/home/nicoleka/DLL-Ass4/adult.arff\"\n",
        "    random_seeds = [42, 123, 456]\n",
        "\n",
        "    detection_results = []\n",
        "    efficacy_results = []\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for seed in random_seeds:\n",
        "        print(f\"\\nRunning experiment with seed {seed}\")\n",
        "        history, synthetic_samples, (X_train, X_test, y_train, y_test) = run_experiment_GAN(\n",
        "            arff_path, seed\n",
        "        )\n",
        "\n",
        "        # Plot training progress\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(history['d_losses'], label='Discriminator')\n",
        "        plt.plot(history['g_losses'], label='Generator')\n",
        "        plt.title(f'Training Progress (Seed {seed})')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.savefig(f'training_progress_seed_{seed}.png')\n",
        "        plt.close()\n",
        "\n",
        "        # Detection Metric\n",
        "        detection_auc = detection_metric(X_train.values, synthetic_samples)\n",
        "        print(f\"Detection AUC (Seed {seed}): {detection_auc:.4f}\")\n",
        "        detection_results.append({\n",
        "            'seed': seed,\n",
        "            'detection_auc': detection_auc\n",
        "        })\n",
        "\n",
        "        # Efficacy Metric\n",
        "        real_auc, synthetic_auc, efficacy_ratio = efficacy_metric(\n",
        "            X_train.values, X_test.values, y_train.values,\n",
        "            synthetic_samples, y_train.values, y_test.values\n",
        "        )\n",
        "        print(f\"Efficacy AUC (Real, Seed {seed}): {real_auc:.4f}\")\n",
        "        print(f\"Efficacy AUC (Synthetic, Seed {seed}): {synthetic_auc:.4f}\")\n",
        "        print(f\"Efficacy Ratio (Seed {seed}): {efficacy_ratio:.4f}\")\n",
        "        efficacy_results.append({\n",
        "            'seed': seed,\n",
        "            'real_auc': real_auc,\n",
        "            'synthetic_auc': synthetic_auc,\n",
        "            'efficacy_ratio': efficacy_ratio\n",
        "        })\n",
        "\n",
        "    # Summarize results\n",
        "    print(\"\\nSummary of Detection Results:\")\n",
        "    for result in detection_results:\n",
        "        print(f\"Seed {result['seed']}: Detection AUC = {result['detection_auc']:.4f}\")\n",
        "\n",
        "    print(\"\\nSummary of Efficacy Results:\")\n",
        "    for result in efficacy_results:\n",
        "        print(f\"Seed {result['seed']}: Real AUC = {result['real_auc']:.4f}, Synthetic AUC = {result['synthetic_auc']:.4f}, Ratio = {result['efficacy_ratio']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLMRPgUHWs3E",
        "outputId": "389d40e4-3d1c-45ad-be48-36d412e0d527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running cGAN experiment with seed 42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "Epoch 1/100: 100%|██████████| 407/407 [00:02<00:00, 180.58it/s, D_loss=0.5833, G_loss=7.7545]\n",
            "Epoch 2/100: 100%|██████████| 407/407 [00:02<00:00, 190.82it/s, D_loss=0.3644, G_loss=7.0087]\n",
            "Epoch 3/100: 100%|██████████| 407/407 [00:02<00:00, 191.92it/s, D_loss=0.3290, G_loss=5.5325]\n",
            "Epoch 4/100: 100%|██████████| 407/407 [00:02<00:00, 193.20it/s, D_loss=0.3373, G_loss=4.3142]\n",
            "Epoch 5/100: 100%|██████████| 407/407 [00:02<00:00, 191.82it/s, D_loss=0.3830, G_loss=3.0155]\n",
            "Epoch 6/100: 100%|██████████| 407/407 [00:02<00:00, 194.29it/s, D_loss=0.3814, G_loss=2.8175]\n",
            "Epoch 7/100: 100%|██████████| 407/407 [00:02<00:00, 192.10it/s, D_loss=0.3947, G_loss=2.7003]\n",
            "Epoch 8/100: 100%|██████████| 407/407 [00:02<00:00, 190.62it/s, D_loss=0.4130, G_loss=2.6046]\n",
            "Epoch 9/100: 100%|██████████| 407/407 [00:02<00:00, 191.36it/s, D_loss=0.4132, G_loss=2.5679]\n",
            "Epoch 10/100: 100%|██████████| 407/407 [00:02<00:00, 193.22it/s, D_loss=0.4027, G_loss=2.5297]\n",
            "Epoch 11/100: 100%|██████████| 407/407 [00:02<00:00, 194.23it/s, D_loss=0.4122, G_loss=2.4367]\n",
            "Epoch 12/100: 100%|██████████| 407/407 [00:02<00:00, 192.16it/s, D_loss=0.4028, G_loss=2.4125]\n",
            "Epoch 13/100: 100%|██████████| 407/407 [00:02<00:00, 193.71it/s, D_loss=0.4012, G_loss=2.3976]\n",
            "Epoch 14/100: 100%|██████████| 407/407 [00:02<00:00, 195.15it/s, D_loss=0.4051, G_loss=2.3591]\n",
            "Epoch 15/100: 100%|██████████| 407/407 [00:02<00:00, 194.45it/s, D_loss=0.4076, G_loss=2.3296]\n",
            "Epoch 16/100: 100%|██████████| 407/407 [00:02<00:00, 194.52it/s, D_loss=0.4088, G_loss=2.3170]\n",
            "Epoch 17/100: 100%|██████████| 407/407 [00:02<00:00, 192.67it/s, D_loss=0.4096, G_loss=2.2935]\n",
            "Epoch 18/100: 100%|██████████| 407/407 [00:02<00:00, 192.83it/s, D_loss=0.4103, G_loss=2.2948]\n",
            "Epoch 19/100: 100%|██████████| 407/407 [00:02<00:00, 192.19it/s, D_loss=0.4083, G_loss=2.2870]\n",
            "Epoch 20/100: 100%|██████████| 407/407 [00:02<00:00, 195.67it/s, D_loss=0.4111, G_loss=2.2740]\n",
            "Epoch 21/100: 100%|██████████| 407/407 [00:02<00:00, 196.85it/s, D_loss=0.4109, G_loss=2.2820]\n",
            "Epoch 22/100: 100%|██████████| 407/407 [00:02<00:00, 192.99it/s, D_loss=0.4112, G_loss=2.2618]\n",
            "Epoch 23/100: 100%|██████████| 407/407 [00:02<00:00, 194.16it/s, D_loss=0.4126, G_loss=2.2604]\n",
            "Epoch 24/100: 100%|██████████| 407/407 [00:02<00:00, 192.57it/s, D_loss=0.4105, G_loss=2.2611]\n",
            "Epoch 25/100: 100%|██████████| 407/407 [00:02<00:00, 193.79it/s, D_loss=0.4104, G_loss=2.2658]\n",
            "Epoch 26/100: 100%|██████████| 407/407 [00:02<00:00, 191.94it/s, D_loss=0.4125, G_loss=2.2550]\n",
            "Epoch 27/100: 100%|██████████| 407/407 [00:02<00:00, 193.56it/s, D_loss=0.4420, G_loss=2.2659]\n",
            "Epoch 28/100: 100%|██████████| 407/407 [00:02<00:00, 191.63it/s, D_loss=0.4104, G_loss=2.2645]\n",
            "Epoch 29/100: 100%|██████████| 407/407 [00:02<00:00, 193.39it/s, D_loss=0.4104, G_loss=2.2578]\n",
            "Epoch 30/100: 100%|██████████| 407/407 [00:02<00:00, 190.89it/s, D_loss=0.4102, G_loss=2.2635]\n",
            "Epoch 31/100: 100%|██████████| 407/407 [00:02<00:00, 194.01it/s, D_loss=0.4101, G_loss=2.2563]\n",
            "Epoch 32/100: 100%|██████████| 407/407 [00:02<00:00, 194.74it/s, D_loss=0.4072, G_loss=2.2767]\n",
            "Epoch 33/100: 100%|██████████| 407/407 [00:02<00:00, 188.70it/s, D_loss=0.4091, G_loss=2.2728]\n",
            "Epoch 34/100: 100%|██████████| 407/407 [00:02<00:00, 192.16it/s, D_loss=0.4098, G_loss=2.2650]\n",
            "Epoch 35/100: 100%|██████████| 407/407 [00:02<00:00, 192.55it/s, D_loss=0.4076, G_loss=2.2785]\n",
            "Epoch 36/100: 100%|██████████| 407/407 [00:02<00:00, 189.80it/s, D_loss=0.4078, G_loss=2.2755]\n",
            "Epoch 37/100: 100%|██████████| 407/407 [00:02<00:00, 194.15it/s, D_loss=0.4087, G_loss=2.2773]\n",
            "Epoch 38/100: 100%|██████████| 407/407 [00:02<00:00, 194.90it/s, D_loss=0.4063, G_loss=2.2882]\n",
            "Epoch 39/100: 100%|██████████| 407/407 [00:02<00:00, 193.40it/s, D_loss=0.4066, G_loss=2.2964]\n",
            "Epoch 40/100: 100%|██████████| 407/407 [00:02<00:00, 192.83it/s, D_loss=0.4060, G_loss=2.3031]\n",
            "Epoch 41/100: 100%|██████████| 407/407 [00:02<00:00, 194.29it/s, D_loss=0.4044, G_loss=2.3097]\n",
            "Epoch 42/100: 100%|██████████| 407/407 [00:02<00:00, 192.39it/s, D_loss=0.4048, G_loss=2.3080]\n",
            "Epoch 43/100: 100%|██████████| 407/407 [00:02<00:00, 192.32it/s, D_loss=0.4062, G_loss=2.3118]\n",
            "Epoch 44/100: 100%|██████████| 407/407 [00:02<00:00, 192.61it/s, D_loss=0.4042, G_loss=2.3238]\n",
            "Epoch 45/100: 100%|██████████| 407/407 [00:02<00:00, 192.95it/s, D_loss=0.4032, G_loss=2.3075]\n",
            "Epoch 46/100: 100%|██████████| 407/407 [00:02<00:00, 192.88it/s, D_loss=0.4019, G_loss=2.3311]\n",
            "Epoch 47/100: 100%|██████████| 407/407 [00:02<00:00, 191.82it/s, D_loss=0.4009, G_loss=2.3513]\n",
            "Epoch 48/100: 100%|██████████| 407/407 [00:02<00:00, 193.70it/s, D_loss=0.3991, G_loss=2.3525]\n",
            "Epoch 49/100: 100%|██████████| 407/407 [00:02<00:00, 189.82it/s, D_loss=0.3968, G_loss=2.3662]\n",
            "Epoch 50/100: 100%|██████████| 407/407 [00:02<00:00, 194.32it/s, D_loss=0.3947, G_loss=2.3606]\n",
            "Epoch 51/100: 100%|██████████| 407/407 [00:02<00:00, 190.79it/s, D_loss=0.3978, G_loss=2.3718]\n",
            "Epoch 52/100: 100%|██████████| 407/407 [00:02<00:00, 193.94it/s, D_loss=0.3944, G_loss=2.3760]\n",
            "Epoch 53/100: 100%|██████████| 407/407 [00:02<00:00, 195.26it/s, D_loss=0.3947, G_loss=2.3774]\n",
            "Epoch 54/100: 100%|██████████| 407/407 [00:02<00:00, 193.83it/s, D_loss=0.3886, G_loss=2.3900]\n",
            "Epoch 55/100: 100%|██████████| 407/407 [00:02<00:00, 192.61it/s, D_loss=0.3928, G_loss=2.4011]\n",
            "Epoch 56/100: 100%|██████████| 407/407 [00:02<00:00, 192.13it/s, D_loss=0.3882, G_loss=2.4141]\n",
            "Epoch 57/100: 100%|██████████| 407/407 [00:02<00:00, 194.11it/s, D_loss=0.3907, G_loss=2.4053]\n",
            "Epoch 58/100: 100%|██████████| 407/407 [00:02<00:00, 190.92it/s, D_loss=0.3891, G_loss=2.4080]\n",
            "Epoch 59/100: 100%|██████████| 407/407 [00:02<00:00, 191.52it/s, D_loss=0.3887, G_loss=2.4150]\n",
            "Epoch 60/100: 100%|██████████| 407/407 [00:02<00:00, 193.96it/s, D_loss=0.3878, G_loss=2.4327]\n",
            "Epoch 61/100: 100%|██████████| 407/407 [00:02<00:00, 194.37it/s, D_loss=0.3862, G_loss=2.4349]\n",
            "Epoch 62/100: 100%|██████████| 407/407 [00:02<00:00, 191.91it/s, D_loss=0.3853, G_loss=2.4504]\n",
            "Epoch 63/100: 100%|██████████| 407/407 [00:02<00:00, 191.03it/s, D_loss=0.3825, G_loss=2.4735]\n",
            "Epoch 64/100: 100%|██████████| 407/407 [00:02<00:00, 192.30it/s, D_loss=0.3809, G_loss=2.4930]\n",
            "Epoch 65/100: 100%|██████████| 407/407 [00:02<00:00, 190.43it/s, D_loss=0.3819, G_loss=2.4808]\n",
            "Epoch 66/100: 100%|██████████| 407/407 [00:02<00:00, 193.48it/s, D_loss=0.3813, G_loss=2.4959]\n",
            "Epoch 67/100: 100%|██████████| 407/407 [00:02<00:00, 195.08it/s, D_loss=0.3800, G_loss=2.5063]\n",
            "Epoch 68/100: 100%|██████████| 407/407 [00:02<00:00, 195.23it/s, D_loss=0.3762, G_loss=2.5444]\n",
            "Epoch 69/100: 100%|██████████| 407/407 [00:02<00:00, 197.38it/s, D_loss=0.3758, G_loss=2.5601]\n",
            "Epoch 70/100: 100%|██████████| 407/407 [00:02<00:00, 196.74it/s, D_loss=0.3752, G_loss=2.5684]\n",
            "Epoch 71/100: 100%|██████████| 407/407 [00:02<00:00, 190.25it/s, D_loss=0.3739, G_loss=2.6082]\n",
            "Epoch 72/100: 100%|██████████| 407/407 [00:02<00:00, 193.74it/s, D_loss=0.3750, G_loss=2.6054]\n",
            "Epoch 73/100: 100%|██████████| 407/407 [00:02<00:00, 190.85it/s, D_loss=0.3761, G_loss=2.5993]\n",
            "Epoch 74/100: 100%|██████████| 407/407 [00:02<00:00, 192.11it/s, D_loss=0.3720, G_loss=2.6268]\n",
            "Epoch 75/100: 100%|██████████| 407/407 [00:02<00:00, 194.77it/s, D_loss=0.3704, G_loss=2.6732]\n",
            "Epoch 76/100: 100%|██████████| 407/407 [00:02<00:00, 190.31it/s, D_loss=0.3707, G_loss=2.6872]\n",
            "Epoch 77/100: 100%|██████████| 407/407 [00:02<00:00, 192.71it/s, D_loss=0.3667, G_loss=2.7174]\n",
            "Epoch 78/100: 100%|██████████| 407/407 [00:02<00:00, 194.06it/s, D_loss=0.3693, G_loss=2.7406]\n",
            "Epoch 79/100: 100%|██████████| 407/407 [00:02<00:00, 191.95it/s, D_loss=0.3673, G_loss=2.7807]\n",
            "Epoch 80/100: 100%|██████████| 407/407 [00:02<00:00, 191.90it/s, D_loss=0.3669, G_loss=2.7850]\n",
            "Epoch 81/100: 100%|██████████| 407/407 [00:02<00:00, 192.32it/s, D_loss=0.3646, G_loss=2.8179]\n",
            "Epoch 82/100: 100%|██████████| 407/407 [00:02<00:00, 192.44it/s, D_loss=0.3651, G_loss=2.8312]\n",
            "Epoch 83/100: 100%|██████████| 407/407 [00:02<00:00, 193.44it/s, D_loss=0.3639, G_loss=2.8559]\n",
            "Epoch 84/100: 100%|██████████| 407/407 [00:02<00:00, 188.58it/s, D_loss=0.3638, G_loss=2.8584]\n",
            "Epoch 85/100: 100%|██████████| 407/407 [00:02<00:00, 191.40it/s, D_loss=0.3630, G_loss=2.8879]\n",
            "Epoch 86/100: 100%|██████████| 407/407 [00:02<00:00, 192.17it/s, D_loss=0.3550, G_loss=2.9606]\n",
            "Epoch 87/100: 100%|██████████| 407/407 [00:02<00:00, 192.92it/s, D_loss=0.3610, G_loss=2.9252]\n",
            "Epoch 88/100: 100%|██████████| 407/407 [00:02<00:00, 193.09it/s, D_loss=0.3589, G_loss=2.9652]\n",
            "Epoch 89/100: 100%|██████████| 407/407 [00:02<00:00, 191.50it/s, D_loss=0.3568, G_loss=2.9940]\n",
            "Epoch 90/100: 100%|██████████| 407/407 [00:02<00:00, 191.61it/s, D_loss=0.3554, G_loss=3.0185]\n",
            "Epoch 91/100: 100%|██████████| 407/407 [00:02<00:00, 193.43it/s, D_loss=0.3566, G_loss=3.0631]\n",
            "Epoch 92/100: 100%|██████████| 407/407 [00:02<00:00, 193.90it/s, D_loss=0.3533, G_loss=3.0490]\n",
            "Epoch 93/100: 100%|██████████| 407/407 [00:02<00:00, 192.91it/s, D_loss=0.3524, G_loss=3.0990]\n",
            "Epoch 94/100: 100%|██████████| 407/407 [00:02<00:00, 194.66it/s, D_loss=0.3482, G_loss=3.1294]\n",
            "Epoch 95/100: 100%|██████████| 407/407 [00:02<00:00, 191.41it/s, D_loss=0.3512, G_loss=3.1325]\n",
            "Epoch 96/100: 100%|██████████| 407/407 [00:02<00:00, 192.06it/s, D_loss=0.3547, G_loss=3.1344]\n",
            "Epoch 97/100: 100%|██████████| 407/407 [00:02<00:00, 193.41it/s, D_loss=0.3536, G_loss=3.1255]\n",
            "Epoch 98/100: 100%|██████████| 407/407 [00:02<00:00, 194.72it/s, D_loss=0.3504, G_loss=3.2184]\n",
            "Epoch 99/100: 100%|██████████| 407/407 [00:02<00:00, 195.10it/s, D_loss=0.3472, G_loss=3.2225]\n",
            "Epoch 100/100: 100%|██████████| 407/407 [00:02<00:00, 192.93it/s, D_loss=0.3519, G_loss=3.2787]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detection AUC (Seed 42): 1.0000\n",
            "Efficacy AUC (Real, Seed 42): 0.9071\n",
            "Efficacy AUC (Synthetic, Seed 42): 0.7127\n",
            "Efficacy Ratio (Seed 42): 0.7857\n",
            "\n",
            "Running cGAN experiment with seed 123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "Epoch 1/100: 100%|██████████| 407/407 [00:02<00:00, 193.58it/s, D_loss=0.5757, G_loss=8.0034]\n",
            "Epoch 2/100: 100%|██████████| 407/407 [00:02<00:00, 193.15it/s, D_loss=0.3364, G_loss=6.9197]\n",
            "Epoch 3/100: 100%|██████████| 407/407 [00:02<00:00, 191.95it/s, D_loss=0.2884, G_loss=6.1373]\n",
            "Epoch 4/100: 100%|██████████| 407/407 [00:02<00:00, 193.99it/s, D_loss=0.3303, G_loss=4.5479]\n",
            "Epoch 5/100: 100%|██████████| 407/407 [00:02<00:00, 191.25it/s, D_loss=0.3519, G_loss=3.0594]\n",
            "Epoch 6/100: 100%|██████████| 407/407 [00:02<00:00, 192.53it/s, D_loss=0.3445, G_loss=2.9179]\n",
            "Epoch 7/100: 100%|██████████| 407/407 [00:02<00:00, 192.50it/s, D_loss=0.3517, G_loss=2.8586]\n",
            "Epoch 8/100: 100%|██████████| 407/407 [00:02<00:00, 192.08it/s, D_loss=0.3685, G_loss=2.6938]\n",
            "Epoch 9/100: 100%|██████████| 407/407 [00:02<00:00, 190.57it/s, D_loss=0.3684, G_loss=2.6721]\n",
            "Epoch 10/100: 100%|██████████| 407/407 [00:02<00:00, 192.99it/s, D_loss=0.3537, G_loss=2.6228]\n",
            "Epoch 11/100: 100%|██████████| 407/407 [00:02<00:00, 191.43it/s, D_loss=0.3522, G_loss=2.6207]\n",
            "Epoch 12/100: 100%|██████████| 407/407 [00:02<00:00, 192.44it/s, D_loss=0.3506, G_loss=2.5975]\n",
            "Epoch 13/100: 100%|██████████| 407/407 [00:02<00:00, 193.96it/s, D_loss=0.3560, G_loss=2.5337]\n",
            "Epoch 14/100: 100%|██████████| 407/407 [00:02<00:00, 192.83it/s, D_loss=0.3592, G_loss=2.5167]\n",
            "Epoch 15/100: 100%|██████████| 407/407 [00:02<00:00, 189.40it/s, D_loss=0.3525, G_loss=2.5298]\n",
            "Epoch 16/100: 100%|██████████| 407/407 [00:02<00:00, 193.06it/s, D_loss=0.3508, G_loss=2.5090]\n",
            "Epoch 17/100: 100%|██████████| 407/407 [00:02<00:00, 192.53it/s, D_loss=0.3552, G_loss=2.4887]\n",
            "Epoch 18/100: 100%|██████████| 407/407 [00:02<00:00, 192.66it/s, D_loss=0.3520, G_loss=2.4849]\n",
            "Epoch 19/100: 100%|██████████| 407/407 [00:02<00:00, 192.72it/s, D_loss=0.3523, G_loss=2.4908]\n",
            "Epoch 20/100: 100%|██████████| 407/407 [00:02<00:00, 189.37it/s, D_loss=0.3509, G_loss=2.4772]\n",
            "Epoch 21/100: 100%|██████████| 407/407 [00:02<00:00, 194.28it/s, D_loss=0.3505, G_loss=2.4789]\n",
            "Epoch 22/100: 100%|██████████| 407/407 [00:02<00:00, 195.45it/s, D_loss=0.3506, G_loss=2.4782]\n",
            "Epoch 23/100: 100%|██████████| 407/407 [00:02<00:00, 193.02it/s, D_loss=0.3490, G_loss=2.4822]\n",
            "Epoch 24/100: 100%|██████████| 407/407 [00:02<00:00, 189.30it/s, D_loss=0.3486, G_loss=2.4779]\n",
            "Epoch 25/100: 100%|██████████| 407/407 [00:02<00:00, 191.12it/s, D_loss=0.3504, G_loss=2.4772]\n",
            "Epoch 26/100: 100%|██████████| 407/407 [00:02<00:00, 193.00it/s, D_loss=0.3515, G_loss=2.4725]\n",
            "Epoch 27/100: 100%|██████████| 407/407 [00:02<00:00, 191.82it/s, D_loss=0.3534, G_loss=2.4571]\n",
            "Epoch 28/100: 100%|██████████| 407/407 [00:02<00:00, 193.38it/s, D_loss=0.3504, G_loss=2.4672]\n",
            "Epoch 29/100: 100%|██████████| 407/407 [00:02<00:00, 192.01it/s, D_loss=0.3508, G_loss=2.4739]\n",
            "Epoch 30/100: 100%|██████████| 407/407 [00:02<00:00, 192.47it/s, D_loss=0.3515, G_loss=2.4506]\n",
            "Epoch 31/100: 100%|██████████| 407/407 [00:02<00:00, 194.42it/s, D_loss=0.3492, G_loss=2.4722]\n",
            "Epoch 32/100: 100%|██████████| 407/407 [00:02<00:00, 192.54it/s, D_loss=0.3494, G_loss=2.4739]\n",
            "Epoch 33/100: 100%|██████████| 407/407 [00:02<00:00, 194.15it/s, D_loss=0.3502, G_loss=2.4683]\n",
            "Epoch 34/100: 100%|██████████| 407/407 [00:02<00:00, 195.00it/s, D_loss=0.3483, G_loss=2.4788]\n",
            "Epoch 35/100: 100%|██████████| 407/407 [00:02<00:00, 192.33it/s, D_loss=0.3485, G_loss=2.4836]\n",
            "Epoch 36/100: 100%|██████████| 407/407 [00:02<00:00, 190.84it/s, D_loss=0.3475, G_loss=2.4999]\n",
            "Epoch 37/100: 100%|██████████| 407/407 [00:02<00:00, 190.92it/s, D_loss=0.3489, G_loss=2.4871]\n",
            "Epoch 38/100: 100%|██████████| 407/407 [00:02<00:00, 192.30it/s, D_loss=0.3481, G_loss=2.5084]\n",
            "Epoch 39/100: 100%|██████████| 407/407 [00:02<00:00, 191.54it/s, D_loss=0.3470, G_loss=2.4973]\n",
            "Epoch 40/100: 100%|██████████| 407/407 [00:02<00:00, 194.34it/s, D_loss=0.3482, G_loss=2.4906]\n",
            "Epoch 41/100: 100%|██████████| 407/407 [00:02<00:00, 192.17it/s, D_loss=0.3468, G_loss=2.5067]\n",
            "Epoch 42/100: 100%|██████████| 407/407 [00:02<00:00, 192.64it/s, D_loss=0.3452, G_loss=2.5200]\n",
            "Epoch 43/100: 100%|██████████| 407/407 [00:02<00:00, 191.22it/s, D_loss=0.3474, G_loss=2.5063]\n",
            "Epoch 44/100: 100%|██████████| 407/407 [00:02<00:00, 193.41it/s, D_loss=0.3468, G_loss=2.5116]\n",
            "Epoch 45/100: 100%|██████████| 407/407 [00:02<00:00, 191.68it/s, D_loss=0.3468, G_loss=2.5013]\n",
            "Epoch 46/100: 100%|██████████| 407/407 [00:02<00:00, 191.57it/s, D_loss=0.3454, G_loss=2.5251]\n",
            "Epoch 47/100: 100%|██████████| 407/407 [00:02<00:00, 191.80it/s, D_loss=0.3437, G_loss=2.5472]\n",
            "Epoch 48/100: 100%|██████████| 407/407 [00:02<00:00, 194.65it/s, D_loss=0.3465, G_loss=2.5231]\n",
            "Epoch 49/100: 100%|██████████| 407/407 [00:02<00:00, 193.29it/s, D_loss=0.3432, G_loss=2.5472]\n",
            "Epoch 50/100: 100%|██████████| 407/407 [00:02<00:00, 191.55it/s, D_loss=0.3427, G_loss=2.5595]\n",
            "Epoch 51/100: 100%|██████████| 407/407 [00:02<00:00, 190.30it/s, D_loss=0.3424, G_loss=2.5552]\n",
            "Epoch 52/100: 100%|██████████| 407/407 [00:02<00:00, 192.73it/s, D_loss=0.3419, G_loss=2.5747]\n",
            "Epoch 53/100: 100%|██████████| 407/407 [00:02<00:00, 192.49it/s, D_loss=0.3422, G_loss=2.5649]\n",
            "Epoch 54/100: 100%|██████████| 407/407 [00:02<00:00, 196.05it/s, D_loss=0.3412, G_loss=2.5823]\n",
            "Epoch 55/100: 100%|██████████| 407/407 [00:02<00:00, 192.52it/s, D_loss=0.3397, G_loss=2.5928]\n",
            "Epoch 56/100: 100%|██████████| 407/407 [00:02<00:00, 191.54it/s, D_loss=0.3387, G_loss=2.6006]\n",
            "Epoch 57/100: 100%|██████████| 407/407 [00:02<00:00, 192.52it/s, D_loss=0.3404, G_loss=2.5945]\n",
            "Epoch 58/100: 100%|██████████| 407/407 [00:02<00:00, 194.42it/s, D_loss=0.3372, G_loss=2.5961]\n",
            "Epoch 59/100: 100%|██████████| 407/407 [00:02<00:00, 193.31it/s, D_loss=0.3393, G_loss=2.5879]\n",
            "Epoch 60/100: 100%|██████████| 407/407 [00:02<00:00, 192.16it/s, D_loss=0.3397, G_loss=2.5937]\n",
            "Epoch 61/100: 100%|██████████| 407/407 [00:02<00:00, 192.67it/s, D_loss=0.3383, G_loss=2.6019]\n",
            "Epoch 62/100: 100%|██████████| 407/407 [00:02<00:00, 191.68it/s, D_loss=0.3352, G_loss=2.6239]\n",
            "Epoch 63/100: 100%|██████████| 407/407 [00:02<00:00, 191.98it/s, D_loss=0.3349, G_loss=2.6436]\n",
            "Epoch 64/100: 100%|██████████| 407/407 [00:02<00:00, 192.36it/s, D_loss=0.3360, G_loss=2.6376]\n",
            "Epoch 65/100: 100%|██████████| 407/407 [00:02<00:00, 194.99it/s, D_loss=0.5876, G_loss=2.7031]\n",
            "Epoch 66/100: 100%|██████████| 407/407 [00:02<00:00, 192.11it/s, D_loss=0.3469, G_loss=2.5881]\n",
            "Epoch 67/100: 100%|██████████| 407/407 [00:02<00:00, 194.36it/s, D_loss=0.3340, G_loss=2.6173]\n",
            "Epoch 68/100: 100%|██████████| 407/407 [00:02<00:00, 194.65it/s, D_loss=0.3330, G_loss=2.6391]\n",
            "Epoch 69/100: 100%|██████████| 407/407 [00:02<00:00, 196.70it/s, D_loss=0.3292, G_loss=2.6769]\n",
            "Epoch 70/100: 100%|██████████| 407/407 [00:02<00:00, 193.04it/s, D_loss=0.3326, G_loss=2.6557]\n",
            "Epoch 71/100: 100%|██████████| 407/407 [00:02<00:00, 194.78it/s, D_loss=0.3342, G_loss=2.6594]\n",
            "Epoch 72/100: 100%|██████████| 407/407 [00:02<00:00, 194.22it/s, D_loss=0.3342, G_loss=2.6620]\n",
            "Epoch 73/100: 100%|██████████| 407/407 [00:02<00:00, 191.99it/s, D_loss=0.3306, G_loss=2.6807]\n",
            "Epoch 74/100: 100%|██████████| 407/407 [00:02<00:00, 193.32it/s, D_loss=0.3310, G_loss=2.6708]\n",
            "Epoch 75/100: 100%|██████████| 407/407 [00:02<00:00, 193.56it/s, D_loss=0.3309, G_loss=2.6986]\n",
            "Epoch 76/100: 100%|██████████| 407/407 [00:02<00:00, 192.90it/s, D_loss=0.3270, G_loss=2.7402]\n",
            "Epoch 77/100: 100%|██████████| 407/407 [00:02<00:00, 192.51it/s, D_loss=0.3303, G_loss=2.7081]\n",
            "Epoch 78/100: 100%|██████████| 407/407 [00:02<00:00, 190.06it/s, D_loss=0.3287, G_loss=2.7345]\n",
            "Epoch 79/100: 100%|██████████| 407/407 [00:02<00:00, 190.40it/s, D_loss=0.3285, G_loss=2.7416]\n",
            "Epoch 80/100: 100%|██████████| 407/407 [00:02<00:00, 188.41it/s, D_loss=0.3312, G_loss=2.7031]\n",
            "Epoch 81/100: 100%|██████████| 407/407 [00:02<00:00, 195.21it/s, D_loss=0.3246, G_loss=2.7579]\n",
            "Epoch 82/100: 100%|██████████| 407/407 [00:02<00:00, 188.93it/s, D_loss=0.3247, G_loss=2.7717]\n",
            "Epoch 83/100: 100%|██████████| 407/407 [00:02<00:00, 191.37it/s, D_loss=0.3264, G_loss=2.7463]\n",
            "Epoch 84/100: 100%|██████████| 407/407 [00:02<00:00, 194.13it/s, D_loss=0.3269, G_loss=2.7620]\n",
            "Epoch 85/100: 100%|██████████| 407/407 [00:02<00:00, 193.60it/s, D_loss=0.3246, G_loss=2.7745]\n",
            "Epoch 86/100: 100%|██████████| 407/407 [00:02<00:00, 190.77it/s, D_loss=0.3229, G_loss=2.8109]\n",
            "Epoch 87/100: 100%|██████████| 407/407 [00:02<00:00, 191.31it/s, D_loss=0.3218, G_loss=2.8383]\n",
            "Epoch 88/100: 100%|██████████| 407/407 [00:02<00:00, 193.34it/s, D_loss=0.3219, G_loss=2.8413]\n",
            "Epoch 89/100: 100%|██████████| 407/407 [00:02<00:00, 194.54it/s, D_loss=0.3218, G_loss=2.8304]\n",
            "Epoch 90/100: 100%|██████████| 407/407 [00:02<00:00, 192.96it/s, D_loss=0.3235, G_loss=2.8392]\n",
            "Epoch 91/100: 100%|██████████| 407/407 [00:02<00:00, 192.06it/s, D_loss=0.3228, G_loss=2.8502]\n",
            "Epoch 92/100: 100%|██████████| 407/407 [00:02<00:00, 191.99it/s, D_loss=0.3223, G_loss=2.8625]\n",
            "Epoch 93/100: 100%|██████████| 407/407 [00:02<00:00, 193.99it/s, D_loss=0.3226, G_loss=2.8645]\n",
            "Epoch 94/100: 100%|██████████| 407/407 [00:02<00:00, 192.04it/s, D_loss=0.3223, G_loss=2.8963]\n",
            "Epoch 95/100: 100%|██████████| 407/407 [00:02<00:00, 192.76it/s, D_loss=0.3260, G_loss=2.9152]\n",
            "Epoch 96/100: 100%|██████████| 407/407 [00:02<00:00, 191.70it/s, D_loss=0.3201, G_loss=2.8995]\n",
            "Epoch 97/100: 100%|██████████| 407/407 [00:02<00:00, 193.55it/s, D_loss=0.3223, G_loss=2.8714]\n",
            "Epoch 98/100: 100%|██████████| 407/407 [00:02<00:00, 191.86it/s, D_loss=0.3186, G_loss=2.9177]\n",
            "Epoch 99/100: 100%|██████████| 407/407 [00:02<00:00, 192.65it/s, D_loss=0.3184, G_loss=2.9381]\n",
            "Epoch 100/100: 100%|██████████| 407/407 [00:02<00:00, 193.11it/s, D_loss=0.3209, G_loss=2.9137]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detection AUC (Seed 123): 1.0000\n",
            "Efficacy AUC (Real, Seed 123): 0.9001\n",
            "Efficacy AUC (Synthetic, Seed 123): 0.7495\n",
            "Efficacy Ratio (Seed 123): 0.8328\n",
            "\n",
            "Running cGAN experiment with seed 456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "/tmp/ipykernel_3830010/3375388808.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[name] = encoded[:, i]\n",
            "Epoch 1/100: 100%|██████████| 407/407 [00:02<00:00, 194.10it/s, D_loss=0.5908, G_loss=7.6282]\n",
            "Epoch 2/100: 100%|██████████| 407/407 [00:02<00:00, 193.15it/s, D_loss=0.3774, G_loss=6.5744]\n",
            "Epoch 3/100: 100%|██████████| 407/407 [00:02<00:00, 191.80it/s, D_loss=0.3227, G_loss=5.2913]\n",
            "Epoch 4/100: 100%|██████████| 407/407 [00:02<00:00, 192.80it/s, D_loss=0.3048, G_loss=4.1117]\n",
            "Epoch 5/100: 100%|██████████| 407/407 [00:02<00:00, 193.46it/s, D_loss=0.3158, G_loss=3.2742]\n",
            "Epoch 6/100: 100%|██████████| 407/407 [00:02<00:00, 190.44it/s, D_loss=0.3682, G_loss=2.9305]\n",
            "Epoch 7/100: 100%|██████████| 407/407 [00:02<00:00, 193.66it/s, D_loss=0.4157, G_loss=2.6622]\n",
            "Epoch 8/100: 100%|██████████| 407/407 [00:02<00:00, 190.87it/s, D_loss=0.3824, G_loss=2.7254]\n",
            "Epoch 9/100: 100%|██████████| 407/407 [00:02<00:00, 193.98it/s, D_loss=0.3768, G_loss=2.7435]\n",
            "Epoch 10/100: 100%|██████████| 407/407 [00:02<00:00, 193.30it/s, D_loss=0.3747, G_loss=2.6922]\n",
            "Epoch 11/100: 100%|██████████| 407/407 [00:02<00:00, 193.56it/s, D_loss=0.4033, G_loss=2.5768]\n",
            "Epoch 12/100: 100%|██████████| 407/407 [00:02<00:00, 188.29it/s, D_loss=0.4080, G_loss=2.5127]\n",
            "Epoch 13/100: 100%|██████████| 407/407 [00:02<00:00, 192.60it/s, D_loss=0.4121, G_loss=2.4944]\n",
            "Epoch 14/100: 100%|██████████| 407/407 [00:02<00:00, 191.40it/s, D_loss=0.4096, G_loss=2.4514]\n",
            "Epoch 15/100: 100%|██████████| 407/407 [00:02<00:00, 195.20it/s, D_loss=0.3953, G_loss=2.4934]\n",
            "Epoch 16/100: 100%|██████████| 407/407 [00:02<00:00, 193.76it/s, D_loss=0.3942, G_loss=2.4891]\n",
            "Epoch 17/100: 100%|██████████| 407/407 [00:02<00:00, 193.10it/s, D_loss=0.4135, G_loss=2.4193]\n",
            "Epoch 18/100: 100%|██████████| 407/407 [00:02<00:00, 191.35it/s, D_loss=0.4019, G_loss=2.4120]\n",
            "Epoch 19/100: 100%|██████████| 407/407 [00:02<00:00, 192.01it/s, D_loss=0.4031, G_loss=2.3967]\n",
            "Epoch 20/100: 100%|██████████| 407/407 [00:02<00:00, 192.87it/s, D_loss=0.4071, G_loss=2.3689]\n",
            "Epoch 21/100: 100%|██████████| 407/407 [00:02<00:00, 195.66it/s, D_loss=0.4036, G_loss=2.3753]\n",
            "Epoch 22/100: 100%|██████████| 407/407 [00:02<00:00, 193.27it/s, D_loss=0.4021, G_loss=2.3728]\n",
            "Epoch 23/100: 100%|██████████| 407/407 [00:02<00:00, 193.39it/s, D_loss=0.4049, G_loss=2.3711]\n",
            "Epoch 24/100: 100%|██████████| 407/407 [00:02<00:00, 194.27it/s, D_loss=0.4087, G_loss=2.3426]\n",
            "Epoch 25/100: 100%|██████████| 407/407 [00:02<00:00, 194.65it/s, D_loss=0.4174, G_loss=2.3437]\n",
            "Epoch 26/100: 100%|██████████| 407/407 [00:02<00:00, 192.16it/s, D_loss=0.4073, G_loss=2.3433]\n",
            "Epoch 27/100: 100%|██████████| 407/407 [00:02<00:00, 190.83it/s, D_loss=0.4044, G_loss=2.3403]\n",
            "Epoch 28/100: 100%|██████████| 407/407 [00:02<00:00, 192.75it/s, D_loss=0.4080, G_loss=2.3329]\n",
            "Epoch 29/100: 100%|██████████| 407/407 [00:02<00:00, 195.75it/s, D_loss=0.4056, G_loss=2.3446]\n",
            "Epoch 30/100: 100%|██████████| 407/407 [00:02<00:00, 193.57it/s, D_loss=0.4069, G_loss=2.3362]\n",
            "Epoch 31/100: 100%|██████████| 407/407 [00:02<00:00, 192.79it/s, D_loss=0.4072, G_loss=2.3308]\n",
            "Epoch 32/100: 100%|██████████| 407/407 [00:02<00:00, 194.77it/s, D_loss=0.4053, G_loss=2.3443]\n",
            "Epoch 33/100: 100%|██████████| 407/407 [00:02<00:00, 191.96it/s, D_loss=0.4061, G_loss=2.3445]\n",
            "Epoch 34/100: 100%|██████████| 407/407 [00:02<00:00, 194.24it/s, D_loss=0.4084, G_loss=2.3296]\n",
            "Epoch 35/100: 100%|██████████| 407/407 [00:02<00:00, 192.47it/s, D_loss=0.4070, G_loss=2.3374]\n",
            "Epoch 36/100: 100%|██████████| 407/407 [00:02<00:00, 193.18it/s, D_loss=0.4087, G_loss=2.3315]\n",
            "Epoch 37/100: 100%|██████████| 407/407 [00:02<00:00, 192.47it/s, D_loss=0.4088, G_loss=2.3487]\n",
            "Epoch 38/100: 100%|██████████| 407/407 [00:02<00:00, 192.65it/s, D_loss=0.4084, G_loss=2.3319]\n",
            "Epoch 39/100: 100%|██████████| 407/407 [00:02<00:00, 192.22it/s, D_loss=0.4106, G_loss=2.3188]\n",
            "Epoch 40/100: 100%|██████████| 407/407 [00:02<00:00, 192.67it/s, D_loss=0.4115, G_loss=2.3361]\n",
            "Epoch 41/100: 100%|██████████| 407/407 [00:02<00:00, 191.91it/s, D_loss=0.4112, G_loss=2.3264]\n",
            "Epoch 42/100: 100%|██████████| 407/407 [00:02<00:00, 190.66it/s, D_loss=0.4111, G_loss=2.3191]\n",
            "Epoch 43/100: 100%|██████████| 407/407 [00:02<00:00, 192.93it/s, D_loss=0.4172, G_loss=2.3358]\n",
            "Epoch 44/100: 100%|██████████| 407/407 [00:02<00:00, 192.84it/s, D_loss=0.4105, G_loss=2.3474]\n",
            "Epoch 45/100: 100%|██████████| 407/407 [00:02<00:00, 189.83it/s, D_loss=0.4112, G_loss=2.3501]\n",
            "Epoch 46/100: 100%|██████████| 407/407 [00:02<00:00, 193.94it/s, D_loss=0.4106, G_loss=2.3374]\n",
            "Epoch 47/100: 100%|██████████| 407/407 [00:02<00:00, 192.76it/s, D_loss=0.4123, G_loss=2.3431]\n",
            "Epoch 48/100: 100%|██████████| 407/407 [00:02<00:00, 193.78it/s, D_loss=0.4139, G_loss=2.3445]\n",
            "Epoch 49/100: 100%|██████████| 407/407 [00:02<00:00, 191.05it/s, D_loss=0.4192, G_loss=2.3582]\n",
            "Epoch 50/100: 100%|██████████| 407/407 [00:02<00:00, 192.62it/s, D_loss=0.4150, G_loss=2.3375]\n",
            "Epoch 51/100: 100%|██████████| 407/407 [00:02<00:00, 194.73it/s, D_loss=0.4123, G_loss=2.3456]\n",
            "Epoch 52/100: 100%|██████████| 407/407 [00:02<00:00, 195.82it/s, D_loss=0.4132, G_loss=2.3534]\n",
            "Epoch 53/100: 100%|██████████| 407/407 [00:02<00:00, 193.29it/s, D_loss=0.4137, G_loss=2.3684]\n",
            "Epoch 54/100: 100%|██████████| 407/407 [00:02<00:00, 196.86it/s, D_loss=0.4142, G_loss=2.3651]\n",
            "Epoch 55/100: 100%|██████████| 407/407 [00:02<00:00, 194.96it/s, D_loss=0.4128, G_loss=2.3752]\n",
            "Epoch 56/100: 100%|██████████| 407/407 [00:02<00:00, 192.34it/s, D_loss=0.4144, G_loss=2.3743]\n",
            "Epoch 57/100: 100%|██████████| 407/407 [00:02<00:00, 192.94it/s, D_loss=0.4110, G_loss=2.3884]\n",
            "Epoch 58/100: 100%|██████████| 407/407 [00:02<00:00, 192.58it/s, D_loss=0.4115, G_loss=2.3822]\n",
            "Epoch 59/100: 100%|██████████| 407/407 [00:02<00:00, 193.88it/s, D_loss=0.4124, G_loss=2.3783]\n",
            "Epoch 60/100: 100%|██████████| 407/407 [00:02<00:00, 192.59it/s, D_loss=0.4108, G_loss=2.3979]\n",
            "Epoch 61/100: 100%|██████████| 407/407 [00:02<00:00, 194.71it/s, D_loss=0.4107, G_loss=2.3997]\n",
            "Epoch 62/100: 100%|██████████| 407/407 [00:02<00:00, 194.78it/s, D_loss=0.4131, G_loss=2.3935]\n",
            "Epoch 63/100: 100%|██████████| 407/407 [00:02<00:00, 192.23it/s, D_loss=0.4121, G_loss=2.4159]\n",
            "Epoch 64/100: 100%|██████████| 407/407 [00:02<00:00, 192.08it/s, D_loss=0.4111, G_loss=2.4165]\n",
            "Epoch 65/100: 100%|██████████| 407/407 [00:02<00:00, 192.24it/s, D_loss=0.4109, G_loss=2.4153]\n",
            "Epoch 66/100: 100%|██████████| 407/407 [00:02<00:00, 194.54it/s, D_loss=0.4079, G_loss=2.4564]\n",
            "Epoch 67/100: 100%|██████████| 407/407 [00:02<00:00, 189.99it/s, D_loss=0.4116, G_loss=2.4327]\n",
            "Epoch 68/100: 100%|██████████| 407/407 [00:02<00:00, 191.23it/s, D_loss=0.4098, G_loss=2.4334]\n",
            "Epoch 69/100: 100%|██████████| 407/407 [00:02<00:00, 194.22it/s, D_loss=0.4077, G_loss=2.4595]\n",
            "Epoch 70/100: 100%|██████████| 407/407 [00:02<00:00, 193.91it/s, D_loss=0.4120, G_loss=2.4359]\n",
            "Epoch 71/100: 100%|██████████| 407/407 [00:02<00:00, 192.84it/s, D_loss=0.4079, G_loss=2.4619]\n",
            "Epoch 72/100: 100%|██████████| 407/407 [00:02<00:00, 193.13it/s, D_loss=0.4087, G_loss=2.4690]\n",
            "Epoch 73/100: 100%|██████████| 407/407 [00:02<00:00, 194.29it/s, D_loss=0.4061, G_loss=2.4837]\n",
            "Epoch 74/100: 100%|██████████| 407/407 [00:02<00:00, 195.05it/s, D_loss=0.4067, G_loss=2.4784]\n",
            "Epoch 75/100: 100%|██████████| 407/407 [00:02<00:00, 193.70it/s, D_loss=0.4053, G_loss=2.4696]\n",
            "Epoch 76/100: 100%|██████████| 407/407 [00:02<00:00, 190.57it/s, D_loss=0.4072, G_loss=2.4771]\n",
            "Epoch 77/100: 100%|██████████| 407/407 [00:02<00:00, 192.88it/s, D_loss=0.4077, G_loss=2.4978]\n",
            "Epoch 78/100: 100%|██████████| 407/407 [00:02<00:00, 193.13it/s, D_loss=0.4076, G_loss=2.4832]\n",
            "Epoch 79/100: 100%|██████████| 407/407 [00:02<00:00, 192.13it/s, D_loss=0.4033, G_loss=2.5151]\n",
            "Epoch 80/100: 100%|██████████| 407/407 [00:02<00:00, 193.61it/s, D_loss=0.4053, G_loss=2.5034]\n",
            "Epoch 81/100: 100%|██████████| 407/407 [00:02<00:00, 192.86it/s, D_loss=0.4010, G_loss=2.5278]\n",
            "Epoch 82/100: 100%|██████████| 407/407 [00:02<00:00, 188.60it/s, D_loss=0.4041, G_loss=2.4978]\n",
            "Epoch 83/100: 100%|██████████| 407/407 [00:02<00:00, 194.03it/s, D_loss=0.4014, G_loss=2.5385]\n",
            "Epoch 84/100: 100%|██████████| 407/407 [00:02<00:00, 194.87it/s, D_loss=0.4021, G_loss=2.5381]\n",
            "Epoch 85/100: 100%|██████████| 407/407 [00:02<00:00, 192.23it/s, D_loss=0.4024, G_loss=2.5422]\n",
            "Epoch 86/100: 100%|██████████| 407/407 [00:02<00:00, 193.07it/s, D_loss=0.4005, G_loss=2.5346]\n",
            "Epoch 87/100: 100%|██████████| 407/407 [00:02<00:00, 191.97it/s, D_loss=0.4025, G_loss=2.4936]\n",
            "Epoch 88/100: 100%|██████████| 407/407 [00:02<00:00, 189.84it/s, D_loss=0.4009, G_loss=2.5453]\n",
            "Epoch 89/100: 100%|██████████| 407/407 [00:02<00:00, 193.70it/s, D_loss=0.4016, G_loss=2.5405]\n",
            "Epoch 90/100: 100%|██████████| 407/407 [00:02<00:00, 194.67it/s, D_loss=0.4007, G_loss=2.5531]\n",
            "Epoch 91/100: 100%|██████████| 407/407 [00:02<00:00, 191.85it/s, D_loss=0.4018, G_loss=2.5432]\n",
            "Epoch 92/100: 100%|██████████| 407/407 [00:02<00:00, 192.89it/s, D_loss=0.4017, G_loss=2.5508]\n",
            "Epoch 93/100: 100%|██████████| 407/407 [00:02<00:00, 194.48it/s, D_loss=0.3996, G_loss=2.5642]\n",
            "Epoch 94/100: 100%|██████████| 407/407 [00:02<00:00, 190.77it/s, D_loss=0.3993, G_loss=2.5875]\n",
            "Epoch 95/100: 100%|██████████| 407/407 [00:02<00:00, 192.96it/s, D_loss=0.4016, G_loss=2.5584]\n",
            "Epoch 96/100: 100%|██████████| 407/407 [00:02<00:00, 192.23it/s, D_loss=0.3975, G_loss=2.6072]\n",
            "Epoch 97/100: 100%|██████████| 407/407 [00:02<00:00, 192.71it/s, D_loss=0.3962, G_loss=2.6062]\n",
            "Epoch 98/100: 100%|██████████| 407/407 [00:02<00:00, 192.88it/s, D_loss=0.4014, G_loss=2.5639]\n",
            "Epoch 99/100: 100%|██████████| 407/407 [00:02<00:00, 192.02it/s, D_loss=0.3996, G_loss=2.5958]\n",
            "Epoch 100/100: 100%|██████████| 407/407 [00:02<00:00, 191.47it/s, D_loss=0.3996, G_loss=2.5974]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detection AUC (Seed 456): 1.0000\n",
            "Efficacy AUC (Real, Seed 456): 0.9032\n",
            "Efficacy AUC (Synthetic, Seed 456): 0.8048\n",
            "Efficacy Ratio (Seed 456): 0.8911\n",
            "\n",
            "Summary of Detection Results:\n",
            "Seed 42: Detection AUC = 1.0000\n",
            "Seed 123: Detection AUC = 1.0000\n",
            "Seed 456: Detection AUC = 1.0000\n",
            "\n",
            "Summary of Efficacy Results:\n",
            "Seed 42: Real AUC = 0.9071, Synthetic AUC = 0.7127, Ratio = 0.7857\n",
            "Seed 123: Real AUC = 0.9001, Synthetic AUC = 0.7495, Ratio = 0.8328\n",
            "Seed 456: Real AUC = 0.9032, Synthetic AUC = 0.8048, Ratio = 0.8911\n"
          ]
        }
      ],
      "source": [
        "# Example usage for run_experiment_CGAN\n",
        "if __name__ == \"__main__\":\n",
        "    arff_path = \"adult.arff\"\n",
        "    random_seeds = [42, 123, 456]  # Add more seeds if needed\n",
        "\n",
        "    detection_results = []\n",
        "    efficacy_results = []\n",
        "\n",
        "    for seed in random_seeds:\n",
        "        print(f\"\\nRunning cGAN experiment with seed {seed}\")\n",
        "        history, synthetic_samples, (X_train, X_test, y_train, y_test) = run_experiment_CGAN(\n",
        "            arff_path, seed\n",
        "        )\n",
        "\n",
        "        # Plot training progress\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(history['d_losses'], label='Discriminator')\n",
        "        plt.plot(history['g_losses'], label='Generator')\n",
        "        plt.title(f'Training Progress (cGAN, Seed {seed})')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.savefig(f'cgan_training_progress_seed_{seed}.png')\n",
        "        plt.close()\n",
        "\n",
        "        # Detection Metric\n",
        "        detection_auc = detection_metric(X_train.values, synthetic_samples)\n",
        "        print(f\"Detection AUC (Seed {seed}): {detection_auc:.4f}\")\n",
        "        detection_results.append({\n",
        "            'seed': seed,\n",
        "            'detection_auc': detection_auc\n",
        "        })\n",
        "\n",
        "        # Efficacy Metric\n",
        "        real_auc, synthetic_auc, efficacy_ratio = efficacy_metric(\n",
        "            X_train.values, X_test.values, y_train.values,\n",
        "            synthetic_samples, y_train.values, y_test.values\n",
        "        )\n",
        "        print(f\"Efficacy AUC (Real, Seed {seed}): {real_auc:.4f}\")\n",
        "        print(f\"Efficacy AUC (Synthetic, Seed {seed}): {synthetic_auc:.4f}\")\n",
        "        print(f\"Efficacy Ratio (Seed {seed}): {efficacy_ratio:.4f}\")\n",
        "        efficacy_results.append({\n",
        "            'seed': seed,\n",
        "            'real_auc': real_auc,\n",
        "            'synthetic_auc': synthetic_auc,\n",
        "            'efficacy_ratio': efficacy_ratio\n",
        "        })\n",
        "\n",
        "    # Summarize results\n",
        "    print(\"\\nSummary of Detection Results:\")\n",
        "    for result in detection_results:\n",
        "        print(f\"Seed {result['seed']}: Detection AUC = {result['detection_auc']:.4f}\")\n",
        "\n",
        "    print(\"\\nSummary of Efficacy Results:\")\n",
        "    for result in efficacy_results:\n",
        "        print(f\"Seed {result['seed']}: Real AUC = {result['real_auc']:.4f}, Synthetic AUC = {result['synthetic_auc']:.4f}, Ratio = {result['efficacy_ratio']:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}